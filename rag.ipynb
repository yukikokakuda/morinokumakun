{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a16ab85",
   "metadata": {},
   "source": [
    "\n",
    "# Streamlit版を「ジュピター形式」に置き換えた RAG 学習ノートブック  \n",
    "**LangChain + OpenAI + Chroma（＋BM25ハイブリッド）**\n",
    "\n",
    "このノートブックは、元の Streamlit アプリの処理フローを **講義用に段階分解** したものです。  \n",
    "各セルで「何をしているか／なぜ必要か」を説明し、**最終的に同じロジック**（クエリ整形 → ハイブリッド検索 → 生成回答）をノートブック上で再現できるように構成しています。\n",
    "\n",
    "> ⚠️ 実行には OpenAI API Key が必要です（有料課金が発生します）。`.env` ファイルまたは環境変数に設定してからご利用ください。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd1a678",
   "metadata": {},
   "source": [
    "\n",
    "## 学習目標\n",
    "- RAG 構成要素（**分割 → 埋め込み → ベクトルDB（Chroma） → キーワード（BM25） → ハイブリッド検索 → LLM整形**）を理解する  \n",
    "- **社内RAG**を想定した ACL（閲覧権限）や「一般回答フォールバック」の考え方を学ぶ  \n",
    "- **クエリ整形（凝縮・言い換え）**と **根拠付き回答**（引用リスト生成）の実装を追体験する\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9605bd15",
   "metadata": {},
   "source": [
    "# 📘 RAG（Retrieval-Augmented Generation）入門\n",
    "\n",
    "---\n",
    "\n",
    "## 🔍 RAGとは？\n",
    "RAG は **外部データベースから情報を検索（Retrieve）し、その情報を根拠に生成（Generate）する仕組み** です。  \n",
    "単なる生成AI（ChatGPT等）と違い、**手元のドキュメントに基づく回答**が可能です。\n",
    "\n",
    "---\n",
    "\n",
    "## ✨ RAGを使うメリット\n",
    "| 観点 | 従来のLLM | RAGを使ったLLM |\n",
    "|------|-----------|----------------|\n",
    "| **知識の鮮度** | 訓練データ時点までの知識に依存 | 自分で用意した最新ドキュメントを検索して利用可能 |\n",
    "| **専門性** | 汎用知識は得意だが、社内固有情報は弱い | 内部資料やルールを検索 → 高精度に回答 |\n",
    "| **再現性** | 同じ質問でも答えがぶれる | 根拠（context）があるため一貫性が増す |\n",
    "| **透明性** | 出典が不明 | 参照元を明示可能（引用付き回答） |\n",
    "\n",
    "---\n",
    "\n",
    "## ⚙️ RAGの基本フロー\n",
    "\n",
    "```mermaid\n",
    "flowchart LR\n",
    "    A[ユーザーの質問] --> B[クエリ変換/前処理]\n",
    "    B --> C[ドキュメント検索<br>(Vector DB / BM25)]\n",
    "    C --> D[関連文書群（context）]\n",
    "    D --> E[LLMに渡す]\n",
    "    E --> F[回答生成<br>+ 引用]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c203d773",
   "metadata": {},
   "source": [
    "# RAGの精度向上のポイント\n",
    "\n",
    "## ❓ なぜRAGは「惜しい答え」を返すのか\n",
    "- 質問の曖昧さや社内用語で検索がズレる  \n",
    "- チャンク分割やインデックス設計が不十分  \n",
    "- 埋め込みや更新が古く、情報が正しく反映されていない  \n",
    "\n",
    "---\n",
    "\n",
    "## 🔑 RAGでの改善アプローチ方法\n",
    "| 課題 | 改善の方向性 |\n",
    "|------|--------------|\n",
    "| 質問と検索結果がズレる | **クエリリライト** や意味理解による検索強化 |\n",
    "| インデックス設計が不十分 | **適切なチャンク設計**（粒度の調整） |\n",
    "| 埋め込みの鮮度不足 | **最新Embeddingの適用**と定期的な再構築 |\n",
    "| 文書検索の網羅性不足 | **複数Retrieverの併用**（ベクトル＋BM25など） |\n",
    "| 回答の根拠が不透明 | **引用付き回答** で信頼性を担保 |\n",
    "\n",
    "---\n",
    "\n",
    "##  6つの設計アプローチ（代表例）\n",
    "1. **クエリリライト**: 曖昧な質問をLLMで意図に即した検索クエリへ変換  \n",
    "2. **チャンク最適化**: 文書分割の大きさや重複範囲をチューニング  \n",
    "3. **高品質Embedding**: より精度の高いモデルを利用  \n",
    "4. **Retrieverの多様化**: ベクトル検索＋BM25のハイブリッド  \n",
    "5. **フィルタリング**: ユーザー権限やドメインに応じた情報制御  \n",
    "6. **運用設計**: インデックス更新や品質管理の仕組みを定着  \n",
    "\n",
    "---\n",
    "\n",
    "## 📊 まとめ\n",
    "RAGの精度向上は「モデルの性能」だけでなく、  \n",
    "**設計（チャンク・クエリ処理・Retriever選択）と運用** がカギとなる。  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5017e77d",
   "metadata": {},
   "source": [
    "\n",
    "## 0. 依存ライブラリのインストール（必要な場合）\n",
    "\n",
    "> 既に環境が整っていれば **スキップ**して構いません。Google Colab などでは下を実行してください。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17dd3ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# !pip install -U langchain langchain-community langchain-openai chromadb python-dotenv rank_bm25 unstructured\n",
    "# ↑ BM25 は langchain_community の BM25Retriever を利用します（入らない環境では自動的にスキップする実装にしています）。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a97a05",
   "metadata": {},
   "source": [
    "\n",
    "## 1. インポート\n",
    "ipynbファイルでは Streamlit を外し、**ノートブックで読みやすい形**に再構成します。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc984cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HAS_BM25: True\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 目的：\n",
    "#   RAG（Retrieval-Augmented Generation）で使う\n",
    "#   ライブラリ・設定を読み込み、BM25 の有無を確認する最小例\n",
    "#   ※「どの部品が何をするのか」を理解するための導入コード\n",
    "# ============================================\n",
    "\n",
    "import os\n",
    "import re\n",
    "import hashlib\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Optional, Tuple\n",
    "\n",
    "# --------------------------------------------\n",
    "# .env から API キーなどの環境変数を読み込むためのユーティリティ\n",
    "#   - .env に OPENAI_API_KEY=\"sk-...\" のように書いておく\n",
    "#   - 本番コードでは load_dotenv(); os.getenv(\"OPENAI_API_KEY\") と組み合わせる\n",
    "# --------------------------------------------\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# --------------------------------------------\n",
    "# LangChain / RAG の主要部品\n",
    "#  - Document: 1つの文書（本文＋メタデータ）を表現\n",
    "#  - ChatPromptTemplate: LLM へのプロンプトをテンプレ化\n",
    "#  - RecursiveCharacterTextSplitter: 長文を「チャンク」に分割\n",
    "#  - TextLoader: .txt などのファイルを読み込んで Document に変換\n",
    "#  - Chroma: ベクトルDB（埋め込みで検索するデータベース）\n",
    "#  - ChatOpenAI / OpenAIEmbeddings: OpenAI の会話モデル／埋め込みモデル\n",
    "# --------------------------------------------\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "# --------------------------------------------\n",
    "# BM25 は「キーワード一致型」の古典的検索アルゴリズム\n",
    "#  - ベクトル検索（意味検索）と相性がよく、固有名詞などに強い\n",
    "#  - LangChain では BM25Retriever として提供\n",
    "#  - 内部で 'rank-bm25' ライブラリを利用するため、未インストールでも動くように try/except で吸収\n",
    "#    → 入っていれば使う（HAS_BM25=True）、入ってなければスキップ（HAS_BM25=False）\n",
    "# --------------------------------------------\n",
    "try:\n",
    "    from langchain_community.retrievers import BM25Retriever\n",
    "    HAS_BM25 = True\n",
    "except Exception:\n",
    "    BM25Retriever = None  # 型ヒント用（IDE 補完のために None を入れておく）\n",
    "    HAS_BM25 = False\n",
    "\n",
    "# 実行時に BM25 が使えるかを出力（学習用デバッグ）\n",
    "print(\"HAS_BM25:\", HAS_BM25)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9b262d",
   "metadata": {},
   "source": [
    "\n",
    "## 2. 定数とディレクトリ\n",
    "- 埋め込みモデル：`text-embedding-3-small`（1536次元）\n",
    "- 既存のベクトルDBを使い回す場合は **同じ次元**である必要があります\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ea6222a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --------------------------------------------\n",
    "# プロジェクト内の主要フォルダ・設定を定義\n",
    "# --------------------------------------------\n",
    "\n",
    "# BASE_DIR: プロジェクトのルートディレクトリ\n",
    "#   → 実行ファイルが置かれている場所を基準にする\n",
    "BASE_DIR = Path(\".\").resolve()\n",
    "\n",
    "# RES_DIR: 学習対象となるテキストファイルを置くフォルダ\n",
    "#   例: resources/tech0_travel_policy.txt\n",
    "RES_DIR = BASE_DIR / \"resources\"\n",
    "\n",
    "# VECTOR_DIR: ベクトルデータベース（Chroma）の保存先フォルダ\n",
    "#   \"text-embedding-3-small\" モデルを使うので、その名前を含めてフォルダ名を作成\n",
    "VECTOR_DIR = RES_DIR / \"note_text_embedding_3_small\"\n",
    "\n",
    "# PERSIST_DIR: Chroma に渡すときは Path ではなく str 型が必要なので変換\n",
    "PERSIST_DIR = str(VECTOR_DIR)\n",
    "\n",
    "# --------------------------------------------\n",
    "# モデルや検索のパラメータ設定\n",
    "# --------------------------------------------\n",
    "\n",
    "# EMBED_MODEL: OpenAI の埋め込みモデル\n",
    "#   - \"text-embedding-3-small\" は 1536 次元ベクトルを出力\n",
    "#   - 他モデルに変える場合は保存先 (VECTOR_DIR) も変える必要あり\n",
    "EMBED_MODEL = \"text-embedding-3-small\"  # 1536 dims\n",
    "\n",
    "# CHUNK_SIZE: 1つの文書を分割するサイズ（文字数）\n",
    "# CHUNK_OVERLAP: チャンク間で重複させる文字数\n",
    "#   → 検索精度を高めるために前後を少しかぶらせる\n",
    "CHUNK_SIZE = 900\n",
    "CHUNK_OVERLAP = 180\n",
    "\n",
    "# K_VECT: ベクトル検索で上位何件を取るか\n",
    "# K_BM25: BM25検索で上位何件を取るか\n",
    "# REL_THRESHOLD: 検索結果を有効とみなす最小の関連度スコア\n",
    "K_VECT = 20\n",
    "K_BM25 = 10\n",
    "REL_THRESHOLD = 0.28\n",
    "\n",
    "# ACL_CHOICES: アクセス制御リストの選択肢\n",
    "#   → どのユーザーがどの文書を閲覧できるかを制御するためのタグ\n",
    "ACL_CHOICES = [\"public\", \"finance\", \"engineering\", \"sales\"]\n",
    "\n",
    "# --------------------------------------------\n",
    "# 必要なフォルダを自動作成\n",
    "#   exist_ok=True なので、既に存在していてもエラーにならない\n",
    "# --------------------------------------------\n",
    "RES_DIR.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f7017d",
   "metadata": {},
   "source": [
    "\n",
    "## 3. .env / モデル設定\n",
    "`.env` に `OPENAI_API_KEY=...` を入れておくか、環境変数に設定しておきます。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c431992a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --------------------------------------------\n",
    "# 1. .env ファイルを読み込む\n",
    "#   - .env 内に OPENAI_API_KEY=\"sk-...\" を書いておく想定\n",
    "#   - load_dotenv() を呼ぶと os.getenv で取得可能になる\n",
    "# --------------------------------------------\n",
    "load_dotenv()\n",
    "\n",
    "# APIキーを環境変数から取得\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# APIキーが見つからなかった場合の警告\n",
    "if not api_key:\n",
    "    print(\"⚠️ OPENAI_API_KEY が見つかりません。`.env` または環境変数を設定してください。\")\n",
    "\n",
    "# --------------------------------------------\n",
    "# 2. 使用する LLM モデルの指定\n",
    "#   - 今回は、軽量版 \"gpt-4.1-mini\" などに変更することも可能\n",
    "# --------------------------------------------\n",
    "LLM_MODEL = \"gpt-4.1-mini\"\n",
    "\n",
    "# --------------------------------------------\n",
    "# 3. LLM インスタンスの準備\n",
    "#   - ChatOpenAI: LangChain が提供する OpenAI API のラッパー\n",
    "#   - api_key が未設定でもエラーで止まらないように\n",
    "#     → None を代入して「後で設定されたら使える」設計にしている\n",
    "# --------------------------------------------\n",
    "\n",
    "# メインの対話モデル\n",
    "llm = ChatOpenAI(api_key=api_key, model=LLM_MODEL) if api_key else None\n",
    "\n",
    "# クエリ整形用の軽量モデル（例: 質問を短くまとめる）\n",
    "rewriter = ChatOpenAI(api_key=api_key, model=\"gpt-4.1-mini\") if api_key else None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c5d5ba",
   "metadata": {},
   "source": [
    "\n",
    "## 4. UI ヘッダとサイドバーの設計意図\n",
    "\n",
    "### ⚠️ 注意：このセルは Jupyter Notebook では必ずエラーになります ⚠️\n",
    "\n",
    "以下のコードは **Streamlit 専用** の命令（`st.markdown`, `st.sidebar` など）を使っています。  \n",
    "\n",
    "- Jupyter Notebook 上では Streamlit の UI コンポーネントは動作しないため、  \n",
    "  実行すると必ず `NameError: name 'st' is not defined` になります。  \n",
    "\n",
    "このセクションでは、RAG デモの 見た目と操作性 を担う UI を整えます。\n",
    "狙いは次の 3 点です。\n",
    "\n",
    "### RAGデモUIの設計要点\n",
    "\n",
    "| 観点 | 内容 | 体験できるポイント |\n",
    "|------|------|------------------|\n",
    "| **情報設計の可視化** | ヘッダで「このアプリは RAG を体験する場所」と明示 | ユーザーが目的を誤解せず、体験の文脈を理解できる |\n",
    "|  | 画面中央のイラストや紹介文で **社内限定知識（ミャクじぃ／旅費規程）** を提示 | RAGの「内部知識だけに答える」性質を直感的に伝える |\n",
    "| **運用メニューの体験** | **ACL（権限）** 選択 | 「ユーザー属性によって見える情報が変わる」実務的要件を簡易再現 |\n",
    "|  | フォールバック方針切替（a→c→b / a→b→c） | RAGが答えられないときの設計を比較体験できる |\n",
    "|  | 一般回答の許可（allow_general）ON/OFF | OFFにすると **「根拠が無ければ答えない」** 安全設計を確認できる |\n",
    "| **運用オペレーションの導線** | **インデックス再構築ボタン** | resources/ 配下を再読み込み → ベクトルDB再作成。現場での「更新運用」を模擬 |\n",
    "|  | **チャット履歴クリア** | 会話状態を初期化 → 再テストしやすいUIを提供 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893cbdb5",
   "metadata": {},
   "source": [
    "### ⚠️ 注意：くどいですが、以下セルは Jupyter Notebook では必ずエラーになります ⚠️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cacefd63",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'st' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# -----------------------------\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# UIヘッダ\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# -----------------------------\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m      6\u001b[39m \u001b[38;5;66;03m#     シンプルな HTML/CSS を挿入できる\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m#   ・clamp() は画面幅に応じてフォントサイズを自動調整する関数\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[43mst\u001b[49m.markdown(\u001b[33m\"\"\"\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[33m<style>\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[33mh1.app-title\u001b[39m\u001b[33m{\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[33m  font-weight: 800;           /* 太字で目立たせる */\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[33m  line-height: 1.15;          /* 行間 */\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[33m  margin: .2rem 0 .8rem;      /* 上右下左の余白 */\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[33m  /* 画面幅に応じてサイズ調整（最小2.2rem～最大3.6rem）*/\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[33m  font-size: clamp(2.2rem, 4vw + 1rem, 3.6rem);\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[33m}\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[33m/* 単語の途中で改行させたくない要素に付ける */\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[33m.nowrap\u001b[39m\u001b[33m{\u001b[39m\u001b[33m white-space: nowrap; }\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[33m</style>\u001b[39m\n\u001b[32m     20\u001b[39m \n\u001b[32m     21\u001b[39m \u001b[33m<h1 class=\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mapp-title\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m>\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[33m  Streamlit RAG Starter <br/>\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[33m  <span class=\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mnowrap\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m>— LangChain + OpenAI + Chroma</span>\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[33m</h1>\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[33m\"\"\"\u001b[39m, unsafe_allow_html=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# 3カラムレイアウトを作り、中央カラム（幅比 1:2:1 の真ん中）に画像を置く\u001b[39;00m\n\u001b[32m     28\u001b[39m mid = st.columns([\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m1\u001b[39m])[\u001b[32m1\u001b[39m]\n",
      "\u001b[31mNameError\u001b[39m: name 'st' is not defined"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# UIヘッダ\n",
    "# -----------------------------\n",
    "# --- 2段タイトルを HTML/CSS で描画 ---\n",
    "#   ・Streamlit でも st.markdown(unsafe_allow_html=True) を使うと\n",
    "#     シンプルな HTML/CSS を挿入できる\n",
    "#   ・clamp() は画面幅に応じてフォントサイズを自動調整する関数\n",
    "st.markdown(\"\"\"\n",
    "<style>\n",
    "h1.app-title{\n",
    "  font-weight: 800;           /* 太字で目立たせる */\n",
    "  line-height: 1.15;          /* 行間 */\n",
    "  margin: .2rem 0 .8rem;      /* 上右下左の余白 */\n",
    "  /* 画面幅に応じてサイズ調整（最小2.2rem～最大3.6rem）*/\n",
    "  font-size: clamp(2.2rem, 4vw + 1rem, 3.6rem);\n",
    "}\n",
    "/* 単語の途中で改行させたくない要素に付ける */\n",
    ".nowrap{ white-space: nowrap; }\n",
    "</style>\n",
    "\n",
    "<h1 class=\"app-title\">\n",
    "  Streamlit RAG Starter <br/>\n",
    "  <span class=\"nowrap\">— LangChain + OpenAI + Chroma</span>\n",
    "</h1>\n",
    "\"\"\", unsafe_allow_html=True)\n",
    "\n",
    "# 3カラムレイアウトを作り、中央カラム（幅比 1:2:1 の真ん中）に画像を置く\n",
    "mid = st.columns([1, 2, 1])[1]\n",
    "with mid:\n",
    "    # HERO_IMG が存在する場合だけロゴ/キャラ画像を表示\n",
    "    if HERO_IMG.exists():\n",
    "        st.image(str(HERO_IMG), width=280)\n",
    "\n",
    "# ヒーロー文言（RAGの主題を伝える）\n",
    "#   ・Streamlit のテキストだけでは表現しづらい装飾を、HTMLで行う\n",
    "#   ・unsafe_allow_html=True を付けると HTML が反映される\n",
    "st.markdown(\n",
    "    \"\"\"\n",
    "<div style=\"text-align:center; font-weight:700; margin: 8px 0 18px; font-size:1.05rem;\">\n",
    "私はミャクじぃ！世の中、だれも知らない架空のキャラクターじゃ。ChatGPTに聞いても、絶対にワシのことは知らないはず。<br>\n",
    "このアプリにのみ、ミャクじぃに関する情報がRAGとして登録されている。もしRAGの凄さを体験したければ、ミャクじぃについて、質問するのじゃ！Tech0の旅費規程（架空）も登録しているぞ！\n",
    "</div>\n",
    "\"\"\",\n",
    "    unsafe_allow_html=True,\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# サイドバー（運用っぽい制御）\n",
    "# -----------------------------\n",
    "# 受講生が「設定を触りながら挙動を確かめる」ための UI 群。\n",
    "# 実サービスでもよくある “運用メニュー” を想定。\n",
    "st.sidebar.subheader(\"ボット設定\")\n",
    "\n",
    "# ・ユーザーの権限（ACL）を複数選択可能にする\n",
    "#   → 文書メタデータの \"acl\" と突き合わせて表示/検索を制御する想定\n",
    "user_acl = st.sidebar.multiselect(\"あなたの権限（ACL）\", ACL_CHOICES, default=[\"public\"])\n",
    "\n",
    "# ・フォールバック戦略の選択\n",
    "#   a: 明確化質問（Clarify）\n",
    "#   b: 一般回答（General）\n",
    "#   c: エスカレーション（Escalate）\n",
    "#   「安全設計」は a→c→b の順、「使い勝手重視」は a→b→c の順で試す\n",
    "mode = st.sidebar.selectbox(\"フォールバック方針\", [\"安全設計 (a→c→b)\", \"使い勝手重視 (a→b→c)\"])\n",
    "\n",
    "# ・RAGに根拠がないとき、一般知識で答えるのを許可するか（b）\n",
    "#   学習時は OFF で「RAGだけだと答えられない」体験も見せると理解が深まる\n",
    "allow_general = st.sidebar.toggle(\"RAGに無いとき一般回答も許可する（b）\", value=False)\n",
    "st.sidebar.caption(\"a: 明確化質問 / b: 一般回答 / c: エスカレーション\")\n",
    "\n",
    "# -----------------------------\n",
    "# インデックス再構築ボタン\n",
    "# -----------------------------\n",
    "# 目的：\n",
    "#   ・resources/ 配下のテキストを読み直し、ベクトルDB（Chroma）を作り直す\n",
    "#   ・教材では「ファイルを追加/変更→押して更新」という運用フローを体験\n",
    "if st.sidebar.button(\"🔁 インデックス再構築\", help=\"resources配下を再読み込みしてベクトルDBを作り直します\"):\n",
    "    st.cache_resource.clear()                         # キャッシュをクリア\n",
    "    shutil.rmtree(VECTOR_DIR, ignore_errors=True)     # 既存のベクトルDBを削除\n",
    "    st.session_state[\"_reindexed\"] = True             # フラグを立てる\n",
    "    st.rerun()                                        # 画面をリロード（状態反映）\n",
    "\n",
    "# 前段の処理直後に “再構築完了” を一度だけ表示するためのフラグ制御\n",
    "if st.session_state.get(\"_reindexed\"):\n",
    "    st.sidebar.success(\"インデックスを再構築しました。\")\n",
    "    st.session_state[\"_reindexed\"] = False\n",
    "\n",
    "# -----------------------------\n",
    "# チャット履歴のクリア\n",
    "# -----------------------------\n",
    "# 目的：\n",
    "#   ・会話状態をリセットして、初期状態から試し直す\n",
    "st.sidebar.divider()\n",
    "if st.sidebar.button(\n",
    "    \"🧹 チャット履歴をクリア\",\n",
    "    use_container_width=True,\n",
    "    help=\"会話ログを消して最初からやり直します\"\n",
    "):\n",
    "    st.session_state.pop(\"messages\", None)  # ← 履歴（セッション変数）を削除\n",
    "    st.sidebar.success(\"履歴を消去しました。\")\n",
    "    st.rerun()  # 画面を再描画（ボタンのワンクリックで状態反映）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e45d7cb",
   "metadata": {},
   "source": [
    "\n",
    "## 5. 読み込み & チャンク分割ユーティリティ\n",
    "- **RecursiveCharacterTextSplitter** でチャンク化\n",
    "- メタデータには `source / title / chunk / acl / domain` を付与\n",
    "\n",
    "(ポイント)\n",
    "\n",
    "「チャンク」とは？\n",
    "長文を検索に適した大きさに切り分けた「小さな文書のかたまり」。\n",
    "→ 900文字ごとに分け、前後を180文字かぶらせて検索精度を高める。\n",
    "\n",
    "メタデータの役割\n",
    "どのファイルの何番目か、アクセス権限(ACL)は何か、などを一緒に保存することで、後で「根拠付き回答」が可能になる。\n",
    "\n",
    "拡張性\n",
    "今は *.txt しか読んでいないが、*.md や *.pdf を追加できるように設計されている。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f0979ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------\n",
    "# ユーティリティ関数群\n",
    "#   - RAG 用にリソースファイルを読み込む\n",
    "#   - Chroma で扱える形に整形（チャンク分割＋メタデータ付与）\n",
    "# --------------------------------------------\n",
    "\n",
    "def _list_source_paths() -> List[Path]:\n",
    "    \"\"\"\n",
    "    resources フォルダ内のテキストファイル一覧を返す関数。\n",
    "    - 現状は *.txt のみ対象\n",
    "    - 将来的には *.md や *.pdf も追加できる拡張性を残している\n",
    "    \"\"\"\n",
    "    # Path.glob(\"*.txt\") でファイル検索 → sorted で名前順に揃える\n",
    "    return sorted((RES_DIR).glob(\"*.txt\"))\n",
    "\n",
    "\n",
    "def _sanitize_meta(meta: dict) -> dict:\n",
    "    \"\"\"\n",
    "    メタデータを Chroma が受け付ける形式に変換する関数。\n",
    "    - Chroma は str/int/float/bool/None のみ受け付ける仕様\n",
    "    - list や dict などは文字列に変換して保存する\n",
    "    \"\"\"\n",
    "    clean = {}\n",
    "    for k, v in (meta or {}).items():\n",
    "        if isinstance(v, (str, int, float, bool)) or v is None:\n",
    "            clean[k] = v\n",
    "        else:\n",
    "            clean[k] = str(v)  # 受け付けない型は文字列に変換\n",
    "    return clean\n",
    "\n",
    "\n",
    "def _load_and_chunk(paths: List[Path]) -> List[Document]:\n",
    "    \"\"\"\n",
    "    与えられたファイルパス群を読み込み、チャンク分割して Document のリストを返す。\n",
    "    - RecursiveCharacterTextSplitter を使い、900字単位＋180字オーバーラップで分割\n",
    "    - 各チャンクには「どのファイルの何番目か」が分かるメタデータを付与\n",
    "    \"\"\"\n",
    "    # テキストをチャンクに切り分ける分割器を用意\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP)\n",
    "\n",
    "    out: List[Document] = []\n",
    "    for p in paths:\n",
    "        # 1. ファイル読み込み → Document リストを取得\n",
    "        tdocs = TextLoader(str(p), encoding=\"utf-8\").load()\n",
    "\n",
    "        # 2. Document をチャンク分割\n",
    "        splits = splitter.split_documents(tdocs)\n",
    "\n",
    "        # 3. 各チャンクにメタデータを付与\n",
    "        for i, d in enumerate(splits):\n",
    "            d.metadata.update(\n",
    "                _sanitize_meta(\n",
    "                    {\n",
    "                        \"source\": p.name,     # 元ファイル名（例: tech0_travel_policy.txt）\n",
    "                        \"title\": p.stem,      # 拡張子なしファイル名（例: tech0_travel_policy）\n",
    "                        \"chunk\": i,           # チャンク番号\n",
    "                        \"acl\": \"public\",      # ACL: 今は固定値 \"public\"\n",
    "                        \"domain\": \"internal-policy\",  # ドメイン分類（例: 社内規程）\n",
    "                    }\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # 4. 加工済みチャンクを出力リストに追加\n",
    "        out.extend(splits)\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0033364c",
   "metadata": {},
   "source": [
    "\n",
    "## 6. ベクトルストア & BM25 の構築（キャッシュ再利用あり）\n",
    "\n",
    "この部分では、**検索の土台となるインデックス（索引）**を作成します。\n",
    "\n",
    "【ベクトルストア（Chroma）】\n",
    "\n",
    "OpenAI Embeddings で文書をベクトル化（意味を数値化）。\n",
    "永続保存フォルダ（resources/note_text_embedding_3_small/）に格納。\n",
    "既にフォルダが存在すれば再利用し、壊れていれば削除して再構築。\n",
    "\n",
    "【BM25Retriever（オプション）】\n",
    "\n",
    "古典的な キーワード一致検索。\n",
    "固有名詞や Embeddings が苦手なクエリを補完する。\n",
    "rank-bm25 がインストールされている場合のみ有効。\n",
    "\n",
    "【返り値】\n",
    "\n",
    "VS: ベクトルストア（Chroma インスタンス）\n",
    "BM25: BM25Retriever（または None）\n",
    "ALL_DOCS: すべてのチャンク化済みドキュメント\n",
    "\n",
    "### build_indices() の返り値\n",
    "\n",
    "| 返り値 | 型 | 役割 | イメージ / たとえ |\n",
    "|--------|----|------|-------------------|\n",
    "| **VS** | `Chroma` | 意味ベースの検索を行うベクトルデータベース | AI 司書が「意味」で似ている本を探してくれる |\n",
    "| **BM25** | `BM25Retriever` または `None` | キーワードベースの検索を行う補完装置 | 図書カードを使って単語で探す昔ながらの検索 |\n",
    "| **ALL_DOCS** | `List[Document]` | 検索対象となる全チャンク化済み文書 | 図書館の本棚に並んでいる全ての本 |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e943170",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\diamo\\AppData\\Local\\Temp\\ipykernel_6332\\2685002047.py:40: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the langchain-chroma package and should be used instead. To use it run `pip install -U langchain-chroma` and import as `from langchain_chroma import Chroma`.\n",
      "  vs = Chroma(embedding_function=embeddings, persist_directory=PERSIST_DIR)\n",
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event CollectionGetEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chroma OK / Chunks: 5\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------\n",
    "# ベクトルストア（Chroma）＋BM25 の構築関数\n",
    "#   - ドキュメントを読み込み、埋め込みベクトル化して保存\n",
    "#   - 既存DBがあれば再利用、無効なら再構築\n",
    "#   - 追加で BM25Retriever も準備\n",
    "# --------------------------------------------\n",
    "def build_indices() -> Tuple[Any, Optional[Any], List[Document]]:\n",
    "    \"\"\"\n",
    "    returns:\n",
    "        VS        : ベクトルストア (Chroma)\n",
    "        BM25      : BM25Retriever (オプション、無い場合は None)\n",
    "        ALL_DOCS  : 読み込んだ全チャンク（Document のリスト）\n",
    "    \"\"\"\n",
    "\n",
    "    # OpenAI の埋め込みモデルを初期化\n",
    "    #  - ここで指定した model (1536次元) を使って Chroma に保存される\n",
    "    embeddings = OpenAIEmbeddings(api_key=os.getenv(\"OPENAI_API_KEY\"), model=EMBED_MODEL)\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # 内部関数: リソースフォルダから読み直して再構築する処理\n",
    "    # ----------------------------------------\n",
    "    def rebuild() -> Tuple[Any, List[Document]]:\n",
    "        paths = _list_source_paths()  # resources/*.txt を取得\n",
    "        if not paths:\n",
    "            raise FileNotFoundError(f\"{RES_DIR} に *.txt がありません。\")\n",
    "\n",
    "        docs_ = _load_and_chunk(paths)  # チャンク化\n",
    "        if not docs_:\n",
    "            raise ValueError(\"読み込んだドキュメントが0件です。ファイル内容/文字コードを確認してください。\")\n",
    "\n",
    "        # Chroma に新規ベクトルDBを作成（persist_directory に保存される）\n",
    "        vs_ = Chroma.from_documents(documents=docs_, embedding=embeddings, persist_directory=PERSIST_DIR)\n",
    "        return vs_, docs_\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # 既存のベクトルDBを使うか、再構築するかを判定\n",
    "    # ----------------------------------------\n",
    "    if VECTOR_DIR.exists():\n",
    "        # 既存のDBを開く\n",
    "        vs = Chroma(embedding_function=embeddings, persist_directory=PERSIST_DIR)\n",
    "        try:\n",
    "            # _collection.count() で保存件数を確認\n",
    "            n = vs._collection.count()\n",
    "        except Exception:\n",
    "            n = 0\n",
    "\n",
    "        if n == 0:\n",
    "            # DBはあるが中身が壊れている → フォルダを削除して再構築\n",
    "            shutil.rmtree(VECTOR_DIR, ignore_errors=True)\n",
    "            vs, docs = rebuild()\n",
    "        else:\n",
    "            # 既存のコレクションを取得し、Document リストに変換\n",
    "            raw = vs._collection.get(include=[\"metadatas\", \"documents\"])\n",
    "            docs = [\n",
    "                Document(page_content=c, metadata=(m or {}))\n",
    "                for c, m in zip(raw.get(\"documents\", []), raw.get(\"metadatas\", []))\n",
    "            ]\n",
    "            # もし Document が空なら、再構築\n",
    "            if not docs:\n",
    "                shutil.rmtree(VECTOR_DIR, ignore_errors=True)\n",
    "                vs, docs = rebuild()\n",
    "    else:\n",
    "        # 初回起動 → フォルダが無いので再構築\n",
    "        vs, docs = rebuild()\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # BM25Retriever の準備（任意）\n",
    "    #   - rank-bm25 がインストールされていれば有効\n",
    "    #   - docs が存在する場合のみ初期化\n",
    "    # ----------------------------------------\n",
    "    bm25: Optional[Any] = None\n",
    "    if HAS_BM25 and docs:\n",
    "        try:\n",
    "            bm25 = BM25Retriever.from_documents(docs)  # ドキュメント群からBM25インデックス作成\n",
    "            bm25.k = K_BM25                            # 上位K件を返す設定\n",
    "        except Exception as e:\n",
    "            print(\"BM25 初期化に失敗しました（スキップします）:\", e)\n",
    "            bm25 = None\n",
    "\n",
    "    return vs, bm25, docs\n",
    "\n",
    "\n",
    "# --------------------------------------------\n",
    "# 実行例\n",
    "#   - APIキーが設定されていないとエラーになる\n",
    "#   - 成功すれば Chroma のチャンク件数を出力\n",
    "# --------------------------------------------\n",
    "try:\n",
    "    VS, BM25, ALL_DOCS = build_indices()\n",
    "    print(\"Chroma OK / Chunks:\", len(ALL_DOCS))\n",
    "except Exception as e:\n",
    "    VS = BM25 = ALL_DOCS = None\n",
    "    print(\"⚠️ ベクトルストア構築に失敗しました:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b4368b",
   "metadata": {},
   "source": [
    "\n",
    "## 7. 検索系（クエリ整形 / ルーティング）\n",
    "- **domain_router**：内部／一般のルーティング\n",
    "- **condense_query**：履歴からクエリを1行に凝縮（固有名詞は保持）\n",
    "- **expand_queries**：言い換えを数種類作ってハイブリッド検索の当たりを増やす\n",
    "\n",
    "### クエリ処理ユーティリティ\n",
    "\n",
    "ユーザーの質問をそのまま検索に使うと、「曖昧すぎる」「ノイズが多い」といった問題が出ます。  \n",
    "そこで、以下の4つの関数を用意して、**質問を検索に適した形に変換**します。\n",
    "\n",
    "| 関数名 | 役割 | イメージ |\n",
    "|--------|------|----------|\n",
    "| `domain_router` | 質問の種類を分類（internal / both / general） | 「これは社内固有の話か？一般的な話か？」を仕分ける係 |\n",
    "| `normalize_query` | クエリを正規化（空白や全角スペースを調整） | 入力のゆらぎを揃えて、検索精度を安定させる |\n",
    "| `condense_query` | 履歴を踏まえて短くまとめ直す（固有名詞は残す） | 「長いやりとりを1文に整理する秘書」 |\n",
    "| `expand_queries` | 言い換えを生成して複数クエリに展開 | 「別の言い方でも探してみよう」と検索の抜け漏れを防ぐ |\n",
    "\n",
    "> **ポイント**  \n",
    "> - `condense_query` と `expand_queries` は LLM を活用するので「AIが裏で検索に強い形に変換している」と伝えるとわかりやすい。  \n",
    "> - `domain_router` の分類結果によって「RAGで探すか / 一般知識で答えるか」が変わる。  \n",
    "> - 固有名詞は絶対に消さないことが重要（社内知識は特にユニークだから）。  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce07ed8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------\n",
    "# クエリ処理まわりのユーティリティ関数\n",
    "#   - ユーザーの質問を分類・整形・拡張して検索に適した形にする\n",
    "# --------------------------------------------\n",
    "\n",
    "def domain_router(q: str) -> str:\n",
    "    \"\"\"\n",
    "    質問 (query) が「どの領域に関するものか」を判定する関数。\n",
    "    - internal_kw に含まれる語があれば「社内専用の質問」と判定\n",
    "    - both_kw に含まれる語があれば「社内/一般どちらもありうる質問」と判定\n",
    "    - それ以外は「一般的な質問」と判定\n",
    "    \"\"\"\n",
    "    internal_kw = [\"ミャクじぃ\", \"ひろじぃ\", \"RAG\", \"ベクタ\", \"Chroma\", \"講義\", \"デモ\",\n",
    "                   \"Tech0\", \"旅費\", \"旅費規程\", \"出張\", \"宿泊\", \"日当\"]\n",
    "    if any(k.lower() in q.lower() for k in internal_kw):\n",
    "        return \"internal\"  # 社内情報に関する質問\n",
    "    both_kw = [\"設計\", \"要件\", \"仕様\", \"社内\", \"手順\", \"規程\"]\n",
    "    if any(k in q for k in both_kw):\n",
    "        return \"both\"      # 社内にも一般にも該当しそうな質問\n",
    "    return \"general\"       # 上記以外は一般知識で答えられる質問\n",
    "\n",
    "\n",
    "def normalize_query(q: str) -> str:\n",
    "    \"\"\"\n",
    "    ユーザーの質問文を正規化する関数。\n",
    "    - 全角スペースを半角に置換\n",
    "    - 前後の空白を除去\n",
    "    - 複数の空白を1つにまとめる\n",
    "    \"\"\"\n",
    "    q = q.replace(\"　\", \" \").strip()\n",
    "    return re.sub(r\"\\s+\", \" \", q)\n",
    "\n",
    "\n",
    "def condense_query(history: List[Dict], q: str) -> str:\n",
    "    \"\"\"\n",
    "    履歴を踏まえて質問を1文にまとめ直す関数。\n",
    "    - 固有名詞（例: ミャクじぃ / Tech0）は削除・変換せずそのまま保持\n",
    "    - rewriter (LLM) を使って、検索に適した短い文に整形\n",
    "    - APIキーが未設定なら、そのまま質問を返す（オフライン学習用）\n",
    "    \"\"\"\n",
    "    if rewriter is None:\n",
    "        # APIキーが無い場合でも授業が進められるように設計\n",
    "        return q\n",
    "\n",
    "    # 履歴の直近6件を取り出して \"ユーザー: ... / アシスタント: ...\" の形に整形\n",
    "    last = \"\\n\".join([\n",
    "        f\"{'ユーザー' if m['role']=='user' else 'アシスタント'}: {m['content']}\"\n",
    "        for m in history[-6:]\n",
    "    ])\n",
    "\n",
    "    # プロンプト設計：\n",
    "    #  - 固有名詞は必ず残す\n",
    "    #  - 省略や言い換えはせず、短い日本語1文に整形\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\",\n",
    "         \"あなたは検索クエリ整形の専門家です。\"\n",
    "         \"【絶対条件】固有名詞・社内用語（例: ミャクじぃ/Tech0 等）は必ずそのまま残す。\"\n",
    "         \"省略・言い換え・削除はしない。日本語1文、短く。出力はクエリのみ。\"),\n",
    "        (\"human\", \"履歴:\\n{h}\\n\\n直近質問:\\n{q}\")\n",
    "    ])\n",
    "\n",
    "    out = rewriter.invoke(prompt.format_messages(h=last, q=q)).content.strip()\n",
    "    return out or q  # 万一 LLM が空を返した場合は元の質問を返す\n",
    "\n",
    "\n",
    "def expand_queries(q: str, original: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    質問クエリを「言い換え」して複数バリエーションを生成する関数。\n",
    "    - 元のクエリ (original) を必ず保持（優先度が最も高い）\n",
    "    - 特定の固有名詞（ミャクじぃ）が含まれる場合は手作業で補強パターンを追加\n",
    "    - rewriter があれば LLM に依頼して3つの言い換えを生成\n",
    "    - rewriter が無い場合は簡易的に2パターンを追加\n",
    "    - 最後に重複を除去して最大4件に絞る\n",
    "    \"\"\"\n",
    "    seeds = [original]  # まずは原文をリストに入れる（必ず残す）\n",
    "\n",
    "    # 固有名詞「ミャク」が含まれていれば手作業で候補を追加\n",
    "    if \"ミャク\" in original:\n",
    "        seeds += [\"ミャクじぃ とは\", \"ミャクじぃ キャラクター\", \"ミャクじぃ 説明\"]\n",
    "\n",
    "    if rewriter is None:\n",
    "        # オフライン環境用：シンプルに元クエリ＋「とは」を追加\n",
    "        seeds += [q, q + \" とは\"]\n",
    "    else:\n",
    "        # LLM に「言い換えを3つ」お願いする\n",
    "        p = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"与えたクエリに対し意味の異なる日本語言い換えを3つ、改行で。説明不要。\"),\n",
    "            (\"human\", \"{q}\")\n",
    "        ])\n",
    "        out = rewriter.invoke(p.format_messages(q=q)).content.strip()\n",
    "        seeds += [s.strip(\" ・-•\\n\") for s in out.splitlines() if s.strip()]\n",
    "\n",
    "    # 重複を除去し、先頭から最大4件を返す\n",
    "    seen, ret = set(), []\n",
    "    for s in seeds:\n",
    "        if s not in seen:\n",
    "            seen.add(s)\n",
    "            ret.append(s)\n",
    "    return ret[:4]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003a4193",
   "metadata": {},
   "source": [
    "\n",
    "## 8. ハイブリッド検索（ACLつき）\n",
    "- まず **ベクトル検索**でしきい値以上を確保  \n",
    "- その後 **BM25**（ある場合）で補強し、スコアを調整\n",
    "### ハイブリッド検索の仕組み\n",
    "\n",
    "ユーザーの質問に対して、**意味検索（ベクトル）**と**キーワード検索（BM25）**を組み合わせる関数です。\n",
    "\n",
    "| 関数 | 役割 | イメージ |\n",
    "|------|------|----------|\n",
    "| `uniq_id` | 各ドキュメントに一意のIDを付与 | 「本棚の本に背表紙ラベルを貼る」 |\n",
    "| `_allow` | ユーザー権限（ACL）を確認 | 「閲覧可能な本かチェック」 |\n",
    "| `hybrid_retrieve` | ベクトル検索＋BM25検索の結果を統合し、スコア順に返す | 「AI司書が意味で探し、図書カードで単語でも探す → 上位を提示」 |\n",
    "\n",
    "#### ポイント\n",
    "- **ベクトル検索**  \n",
    "  - 意味が似ている文書を探す（高次元ベクトルの近さ）。\n",
    "- **BM25検索**  \n",
    "  - 単語の出現頻度を基準に探す。固有名詞や略語に強い。\n",
    "- **ACLチェック**  \n",
    "  - 文書ごとに「公開 / finance / engineering …」などの属性を持ち、ユーザーが閲覧できるものだけを返す。\n",
    "- **ハイブリッド**  \n",
    "  - 2つの検索を組み合わせることで「意味にもキーワードにも強い検索」が実現できる。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d12251e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------\n",
    "# 検索ユーティリティ\n",
    "#   - ドキュメントに一意のIDを付与\n",
    "#   - ACLチェック（アクセス制御）\n",
    "#   - ベクトル検索とBM25検索を組み合わせて結果を返す\n",
    "# --------------------------------------------\n",
    "\n",
    "def uniq_id(doc: Document) -> str:\n",
    "    \"\"\"\n",
    "    1つの Document を一意に識別するIDを生成。\n",
    "    - source（元ファイル名）＋chunk番号 をベースにする\n",
    "    - 内容（先頭200文字）のMD5ハッシュを加えて衝突を防ぐ\n",
    "    例: 'tech0_travel_policy-0-a1b2c3d4...'\n",
    "    \"\"\"\n",
    "    key = f\"{doc.metadata.get('source','')}-{doc.metadata.get('chunk','')}\"\n",
    "    return key + \"-\" + hashlib.md5(doc.page_content[:200].encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "\n",
    "def _allow(meta_acl: Optional[str], user_acl_list: List[str]) -> bool:\n",
    "    \"\"\"\n",
    "    ドキュメントのACL（アクセス権限）を確認。\n",
    "    - meta_acl が None → 全員アクセス可能\n",
    "    - それ以外 → ユーザーの権限リストに含まれているかを判定\n",
    "    \"\"\"\n",
    "    if meta_acl is None:\n",
    "        return True\n",
    "    return str(meta_acl) in set(user_acl_list)\n",
    "\n",
    "\n",
    "def hybrid_retrieve(queries: List[str], acl: List[str]) -> List[Tuple[Document, float, str]]:\n",
    "    \"\"\"\n",
    "    ハイブリッド検索を行う関数。\n",
    "    - ベクトル検索（Chroma）と BM25 検索の両方を実行\n",
    "    - ACLを満たさない文書は除外\n",
    "    - 結果をスコア順に並べ、最大8件を返す\n",
    "\n",
    "    returns: [(Document, relevance_score, \"vect|bm25\"), ...]\n",
    "    \"\"\"\n",
    "    if VS is None:\n",
    "        raise RuntimeError(\"ベクトルストアが未初期化です（OpenAIキーや依存関係を確認）。\")\n",
    "\n",
    "    pool: Dict[str, Tuple[Document, float, str]] = {}\n",
    "\n",
    "    # ---- ベクトル検索（意味ベース） ----\n",
    "    # Chromaのfilter機能は使わず、Python側でACLをチェックする\n",
    "    for q in queries:\n",
    "        docs_scores = VS.similarity_search_with_relevance_scores(q, k=K_VECT)\n",
    "        for d, s in docs_scores:\n",
    "            if not _allow(d.metadata.get(\"acl\"), acl):\n",
    "                continue\n",
    "            uid = uniq_id(d)\n",
    "            # relevance_score がしきい値以上ならプールに追加\n",
    "            if uid not in pool and s >= REL_THRESHOLD:\n",
    "                pool[uid] = (d, float(s), \"vect\")\n",
    "\n",
    "    # ---- BM25検索（キーワードベース、オプション） ----\n",
    "    if BM25:\n",
    "        for q in queries:\n",
    "            for d in BM25.get_relevant_documents(q):\n",
    "                if not _allow(d.metadata.get(\"acl\"), acl):\n",
    "                    continue\n",
    "                uid = uniq_id(d)\n",
    "                if uid not in pool:\n",
    "                    # 初回 → 固定スコア0.30で追加\n",
    "                    pool[uid] = (d, 0.30, \"bm25\")\n",
    "                else:\n",
    "                    # 既にある場合はスコアを上書き（上限0.40）\n",
    "                    old = pool[uid]\n",
    "                    pool[uid] = (old[0], max(old[1], 0.40), old[2])\n",
    "\n",
    "    # ---- スコア降順に並べて上位8件を返す ----\n",
    "    return sorted(pool.values(), key=lambda x: x[1], reverse=True)[:8]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c70c6f",
   "metadata": {},
   "source": [
    "\n",
    "## 9. プロンプト & 回答合成\n",
    "- RAG回答：**context のみ**で答える（一般知識は混ぜない）\n",
    "- 一般回答：ミャクじぃ等の社内固有情報を使わず、一般的に説明\n",
    "- 最後に「参考: タイトル#チャンク…」形式で引用を並べる\n",
    "\n",
    "### 回答生成とフォールバック戦略\n",
    "\n",
    "この部分では、**検索結果をどう答えるか**、そして**答えられなかった場合どうするか**を設計します。\n",
    "\n",
    "| 名前 | 役割 | ポイント |\n",
    "|------|------|----------|\n",
    "| `SYSTEM_RAG` / `PROMPT_RAG` | RAG回答専用のルール | 「与えられた context だけで答える」「根拠がなければ答えない」 |\n",
    "| `SYSTEM_GENERAL` / `PROMPT_GENERAL` | 一般回答用のルール | 社外知識を使うときはこちら。固有の社内キャラ情報は使わない |\n",
    "| `compose_with_citations` | 文書の内容を根拠に回答を作成し、引用を付ける | 回答本文＋最大スコア＋参考情報を返す |\n",
    "| `confidence_check` | 回答の自己信頼度を0〜1で評価 | contextに十分根拠があるかを LLM に自己採点させる |\n",
    "| `fallback_strategy` | RAGで答えられなかったときの方針 | 「Clarify（質問を具体化）」→「General（一般回答）」→「Escalate（窓口へ）」の順 |\n",
    "\n",
    "#### ポリシー切り替え\n",
    "- **安全設計 (a→c→b)**  \n",
    "  Clarify → Escalate → General  \n",
    "  → 「安易に一般回答せず、安全第一で進める」\n",
    "- **使い勝手重視 (a→b→c)**  \n",
    "  Clarify → General → Escalate  \n",
    "  → 「ユーザー体験を優先、まず一般回答を試す」\n",
    "\n",
    "> **まとめ**  \n",
    "> - **RAG回答**: 根拠があるときだけ答える  \n",
    "> - **Confidence Check**: 信頼度が低ければフォールバックへ  \n",
    "> - **フォールバック**: ポリシーに従って Clarify / General / Escalate を実行  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "894307c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------\n",
    "# プロンプト定義（回答のルールを指定するシステムメッセージ）\n",
    "# --------------------------------------------\n",
    "\n",
    "SYSTEM_RAG = \"\"\"あなたは企業内RAGアシスタントです。与えられた context だけを根拠に日本語で簡潔に答えてください。\n",
    "- contextに十分な根拠がない場合は、推測せず「このRAGでは該当情報が見つかりませんでした。」と答えてください。\n",
    "- 社外情報や一般知識を混ぜないでください（フォールバックは別で処理します）。\n",
    "- 箇条書き歓迎。各主張の後に [1], [2] のように参照番号を付け、最後に「参考: タイトル#チャンク…」を列挙してください。\n",
    "\"\"\"\n",
    "\n",
    "# RAG専用のプロンプトテンプレート\n",
    "PROMPT_RAG = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", SYSTEM_RAG),                       # システムメッセージ（ルール）\n",
    "        (\"human\", \"context:\\n{context}\\n\\n質問: {q}\") # ユーザー質問＋RAGの根拠\n",
    "    ]\n",
    ")\n",
    "\n",
    "SYSTEM_GENERAL = \"\"\"あなたは有能な日本語アシスタントです。事実に基づき、簡潔かつ丁寧に回答してください。\n",
    "ミャクじぃ（社内固有）の情報は使わず、一般的な説明のみで回答してください。必要なら注意点も添えてください。\"\"\"\n",
    "\n",
    "# 一般回答用のプロンプトテンプレート\n",
    "PROMPT_GENERAL = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", SYSTEM_GENERAL),\n",
    "        (\"human\", \"{q}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# --------------------------------------------\n",
    "# コンテキスト付き回答の生成\n",
    "# --------------------------------------------\n",
    "def compose_with_citations(q: str, docs: List[Tuple[Document, float, str]]) -> Tuple[str, float, str]:\n",
    "    \"\"\"\n",
    "    文書の内容（context）を根拠に回答を生成し、参照情報も付ける。\n",
    "    returns: (回答本文, 最大関連度スコア, 引用一覧文字列)\n",
    "    \"\"\"\n",
    "    if llm is None:\n",
    "        raise RuntimeError(\"OpenAI LLM が未初期化です。APIキーを設定してください。\")\n",
    "\n",
    "    if not docs:\n",
    "        return \"\", 0.0, \"\"\n",
    "\n",
    "    refs, parts = [], []\n",
    "    # [1] doc_content ... の形でコンテキストをまとめる\n",
    "    for i, (d, s, src) in enumerate(docs, start=1):\n",
    "        parts.append(f\"[{i}] {d.page_content}\")\n",
    "        title = d.metadata.get(\"title\", d.metadata.get(\"source\", \"doc\"))\n",
    "        refs.append(f\"[{i}] {title}#{d.metadata.get('chunk','')}\")\n",
    "\n",
    "    context = \"\\n\\n\".join(parts)\n",
    "    msgs = PROMPT_RAG.format_messages(context=context, q=q)\n",
    "\n",
    "    # LLMに投げて回答を生成\n",
    "    out = llm.invoke(msgs).content\n",
    "\n",
    "    # 最大関連度スコアを計算\n",
    "    max_rel = max(score for _, score, _ in docs)\n",
    "\n",
    "    return out, float(max_rel), \"参考: \" + \", \".join(refs)\n",
    "\n",
    "\n",
    "# --------------------------------------------\n",
    "# 回答の自己信頼度チェック\n",
    "# --------------------------------------------\n",
    "def confidence_check(text: str) -> float:\n",
    "    \"\"\"\n",
    "    LLMに「この回答は社内contextだけで裏付けられているか」を判定させる。\n",
    "    - 出力は0〜1の数値\n",
    "    - 失敗時はデフォルト0.5\n",
    "    \"\"\"\n",
    "    if llm is None:\n",
    "        return 0.5\n",
    "\n",
    "    p = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", \"あなたは回答の自己評価器です。以下の回答が、与えられた社内コンテキストだけで十分に裏付けられているかを0〜1で出力。数値のみ。\"),\n",
    "            (\"human\", \"{ans}\"),\n",
    "        ]\n",
    "    )\n",
    "    try:\n",
    "        s = llm.invoke(p.format_messages(ans=text)).content.strip()\n",
    "        m = re.findall(r\"1(?:\\.0+)?|0\\.\\d+|0\", s)  # 正規表現で数値を抽出\n",
    "        return max(0.0, min(1.0, float(m[0]))) if m else 0.5\n",
    "    except Exception:\n",
    "        return 0.5\n",
    "\n",
    "\n",
    "# --------------------------------------------\n",
    "# フォールバック戦略\n",
    "# --------------------------------------------\n",
    "def fallback_strategy(q: str, policy: str, allow_general_flag: bool) -> str:\n",
    "    \"\"\"\n",
    "    RAGで答えられなかった場合の対応方針を実装。\n",
    "    - clarify: 質問をもっと具体化してもらう\n",
    "    - escalate: 社内窓口にエスカレーション\n",
    "    - general: 一般知識で回答する（許可されている場合のみ）\n",
    "    \"\"\"\n",
    "    clarify = \"もう少し具体的に教えてください。（例：対象範囲／時点／キーワード）\"\n",
    "    escalate = \"社内窓口にエスカレーションしてください（例：#help-desk / 担当: support@example.com）。\"\n",
    "\n",
    "    if llm is None:\n",
    "        general = \"（一般回答は API キー未設定のため省略）\"\n",
    "    else:\n",
    "        general = (\n",
    "            llm.invoke(PROMPT_GENERAL.format_messages(q=q)).content\n",
    "            if allow_general_flag\n",
    "            else \"一般回答は現在オフになっています（設定で有効化できます）。\"\n",
    "        )\n",
    "\n",
    "    # ポリシーによって順序を変える\n",
    "    if policy.startswith(\"安全設計\"):\n",
    "        # 安全性優先： Clarify → Escalate → General\n",
    "        return f\"{clarify}\\n\\n{escalate}\\n\\n{general if allow_general_flag else ''}\".strip()\n",
    "    else:\n",
    "        # 使い勝手優先： Clarify → General → Escalate\n",
    "        return f\"{clarify}\\n\\n{general}\\n\\n{escalate}\".strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfc8a22",
   "metadata": {},
   "source": [
    "\n",
    "## 10. 一問一答関数 `ask()`\n",
    "- ルーティング → 凝縮 → 言い換え → ハイブリッド検索 → RAG回答  \n",
    "- 十分な根拠がなければ **フォールバック**（明確化・一般回答・エスカレーション）\n",
    "\n",
    "### ask() 関数の役割\n",
    "\n",
    "ユーザーからの質問を受け取り、**RAG検索 → 信頼度チェック → フォールバック戦略**の流れで回答を返します。\n",
    "\n",
    "#### 処理の流れ\n",
    "1. **質問の分類と整形**\n",
    "   - `domain_router` で internal / both / general に分類\n",
    "   - `normalize_query` で正規化\n",
    "   - `condense_query` で短い検索クエリに変換\n",
    "   - `expand_queries` で言い換えクエリを追加\n",
    "\n",
    "2. **RAG検索（社内ドメインのみ）**\n",
    "   - `hybrid_retrieve` で Chroma（ベクトル検索）＋BM25（キーワード検索）\n",
    "   - `compose_with_citations` で参照付き回答を作成\n",
    "   - `confidence_check` で回答の信頼度を算出\n",
    "\n",
    "3. **フォールバック処理**\n",
    "   - 回答が無い / 信頼度が低い場合は、ポリシーに応じて  \n",
    "     - Clarify（質問を具体化依頼）  \n",
    "     - General（一般知識で回答、許可時のみ）  \n",
    "     - Escalate（社内窓口にエスカレーション）  \n",
    "\n",
    "4. **最終回答を組み立て**\n",
    "   - 引用情報を本文に追加\n",
    "   - 辞書形式で返却\n",
    "\n",
    "#### 戻り値\n",
    "| キー | 内容 |\n",
    "|------|------|\n",
    "| `answer` | 最終回答文 |\n",
    "| `citations` | 引用情報（「参考: …」） |\n",
    "| `confidence` | 信頼度スコア（0〜1） |\n",
    "| `queries_used` | 実際に使われた検索クエリ一覧 |\n",
    "| `domain` | 質問の分類結果（internal / both / general） |\n",
    "\n",
    "---\n",
    "\n",
    "👉 この関数は「RAGアプリの司令塔」。  \n",
    "質問が来たときに **どの処理を実行し、どのルートで答えるかを決める心臓部**です。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25b68602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------\n",
    "# ask(): ユーザーからの質問を受け取り、RAG＋フォールバックで回答を生成する関数\n",
    "# --------------------------------------------\n",
    "\n",
    "def ask(q_raw: str,\n",
    "        user_acl: Optional[List[str]] = None,\n",
    "        policy_mode: str = \"安全設計 (a→c→b)\",\n",
    "        allow_general: bool = False,\n",
    "        history: Optional[List[Dict]] = None) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Returns: 辞書形式で結果を返す\n",
    "      {\n",
    "        'answer': str,         # 回答本文\n",
    "        'citations': str,      # 引用情報（「参考: …」）\n",
    "        'confidence': float,   # 信頼度スコア（0〜1）\n",
    "        'queries_used': List[str], # 実際に使ったクエリ群\n",
    "        'domain': str          # 質問の分類（internal/both/general）\n",
    "      }\n",
    "    \"\"\"\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # 事前処理（ACLと履歴）\n",
    "    # ----------------------------------------\n",
    "    user_acl = user_acl or [\"public\"]   # デフォルト権限は \"public\"\n",
    "    history = history or []             # 履歴が無ければ空リスト\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # 質問の整形と分類\n",
    "    # ----------------------------------------\n",
    "    domain = domain_router(q_raw)                       # 質問が社内か一般かを判定\n",
    "    q_norm = normalize_query(q_raw)                     # 空白などを正規化\n",
    "    q_condensed = condense_query(history, q_norm)       # 履歴を踏まえて短く整形\n",
    "    queries = expand_queries(q_condensed, original=q_norm)  # 言い換えを含めたクエリ群\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # 初期値の準備\n",
    "    # ----------------------------------------\n",
    "    answer_text = \"\"   # 最終的な回答\n",
    "    citations = \"\"     # 参照情報\n",
    "    conf = 0.0         # 信頼度\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # RAG検索（社内関連ドメインの質問のみ）\n",
    "    # ----------------------------------------\n",
    "    if domain in (\"internal\", \"both\"):\n",
    "        docs = hybrid_retrieve(queries, acl=user_acl)\n",
    "        if docs:\n",
    "            # 参照付き回答を作成\n",
    "            answer_text, relmax, citations = compose_with_citations(q_norm, docs)\n",
    "\n",
    "            # LLMによる自己評価と、検索スコアの平均を信頼度として利用\n",
    "            conf_llm = confidence_check(answer_text)\n",
    "            conf = (relmax + conf_llm) / 2.0\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # フォールバック処理\n",
    "    # ----------------------------------------\n",
    "    if not answer_text or conf < 0.35:   # 回答が無い or 信頼度が低い場合\n",
    "        if domain in (\"general\", \"both\"):   # 一般質問の可能性あり\n",
    "            if allow_general:\n",
    "                if llm is None:\n",
    "                    answer_text = \"（一般回答は API キー未設定のため省略）\"\n",
    "                else:\n",
    "                    # 一般知識回答を LLM に依頼\n",
    "                    answer_text = llm.invoke(\n",
    "                        PROMPT_GENERAL.format_messages(q=q_norm)\n",
    "                    ).content\n",
    "            else:\n",
    "                # 一般回答は禁止 → Clarify/Escalate のみ\n",
    "                answer_text = fallback_strategy(q_norm, policy=policy_mode, allow_general_flag=allow_general)\n",
    "        else:\n",
    "            # internal のみだが回答不可 → Clarify/Escalateへ\n",
    "            answer_text = fallback_strategy(q_norm, policy=policy_mode, allow_general_flag=allow_general)\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # 引用を本文に追記\n",
    "    # ----------------------------------------\n",
    "    if citations:\n",
    "        answer_text = f\"{answer_text}\\n\\n{citations}\"\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # 辞書形式で返却\n",
    "    # ----------------------------------------\n",
    "    return {\n",
    "        \"answer\": answer_text,\n",
    "        \"citations\": citations,\n",
    "        \"confidence\": conf,\n",
    "        \"queries_used\": queries,\n",
    "        \"domain\": domain,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ccc290",
   "metadata": {},
   "source": [
    "\n",
    "## 11. デモ実行\n",
    "\n",
    "### ⚠️ 注意：このセルは 上から順番に実行していただければ動きます（第４章を除く） ⚠️\n",
    "\n",
    "必要に応じて質問文を変えて実行してください。  \n",
    "（API キー未設定の環境では、ベクトルストア構築や LLM 呼び出しが失敗する場合があります）\n",
    "\n",
    "### 実行例: 「ミャクじぃについて教えて」\n",
    "\n",
    "ここでは実際に `ask()` を呼び出して動作を確認します。\n",
    "\n",
    "#### 入力\n",
    "- **質問**: 「ミャクじぃについて教えて」\n",
    "- **ACL**: public\n",
    "- **フォールバック方針**: 安全設計 (a→c→b)\n",
    "- **一般回答**: 無効（allow_general=False）\n",
    "\n",
    "#### 出力される項目\n",
    "| 項目 | 内容 |\n",
    "|------|------|\n",
    "| `domain` | internal / both / general のどれに分類されたか |\n",
    "| `queries_used` | 実際に検索に使ったクエリのリスト |\n",
    "| `answer` | 生成された回答本文 |\n",
    "| `confidence` | 回答の信頼度スコア（0〜1） |\n",
    "\n",
    "#### ポイント\n",
    "- **domain** が `internal` になる → 「ミャクじぃ」は社内固有ワードと判定されたため。  \n",
    "- **queries_used** にはオリジナル質問＋言い換えクエリが含まれる。  \n",
    "- **answer** は RAG から見つかった情報に基づいて回答。根拠が無ければ「該当情報が見つかりませんでした」と返す。  \n",
    "- **confidence** は RAG の検索スコアと自己評価の平均。0.35未満ならフォールバック戦略に移行する。  \n",
    "\n",
    "> この例では「社内専用キャラクターについて質問 → RAGが回答する」流れを実演しています。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f540e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 20 is greater than number of elements in index 5, updating n_results = 5\n",
      "Failed to send telemetry event CollectionQueryEvent: capture() takes 1 positional argument but 3 were given\n",
      "C:\\Users\\diamo\\AppData\\Local\\Temp\\ipykernel_6332\\3474795112.py:47: UserWarning: Relevance scores must be between 0 and 1, got [(Document(metadata={'acl': 'public', 'chunk': 1, 'domain': 'internal-policy', 'source': 'rag.txt', 'title': 'rag'}, page_content='見た目は独特な赤と青をベースにしつつ、ひろじぃの象徴である眼鏡とほんの少しの白髪混じりの眉毛が加わっている。さらに、胸元には「Python」のロゴが脈打つように光っており、手にはノートPCを抱えている。時折そのノートPCは、ラッピング新幹線やJALミャクじぃJETに変形し、最新技術と夢を乗せて未来へ飛び立つという。\\n\\n命名の背景として、「ミャクじぃ」という名前は「命や知恵が脈々と続く」という意味を受け継ぎつつ、人生の後半戦を迎えたひろじぃの親しみやすさを重ね合わせたもの。大阪的なノリと親近感が強く、受講生や仲間からは「ミャクさん」「じぃさん」と愛称で呼ばれることもある。\\n\\n活動の舞台は万博にとどまらず、日常的にオンライン講義やワークショップにも登場し、「AIって何？」「Pythonって何ができるの？」といった質問にユーモラスに答える。エラー画面すら笑いに変える姿は、子どもから大人まで幅広い層に愛されている。また、グッズ展開も盛んで、ミャクじぃ型のUSBメモリや、エラー音が「じぃ〜」と鳴るスマホケースなど、奇抜ながらもユーモアあふれるアイテムが人気を博している。\\n\\n近年は、ラッピング電車や航空機にもミャクじぃが描かれ、「失敗してもええやん、学び続けよう」というメッセージを広めている。海外イベントにも登場し、ベトナムでは「Myakujii-san」と呼ばれ親しまれ、オーストラリアでは「じぃじAI先生」として子どもたちにデジタル教育を伝える活動を行った。'), 0.3788298668096355), (Document(metadata={'acl': 'public', 'chunk': 0, 'domain': 'internal-policy', 'source': 'rag.txt', 'title': 'rag'}, page_content='ミャクじぃは、2025年に大阪・夢洲で開催されている大阪・関西万博の公式キャラクター「ミャクミャク」とは一切関係ありません。Tech0でITを勉強しはじめたばかりの40歳のおじさん「ひろじぃ」から誕生した、不思議でユーモラスな仮想キャラクターである。その存在は、まるで細胞のように脈打ちながら歴史と知恵を受け継ぎ、同時に学びと挑戦を重ねて進化する姿を象徴している。\\n\\n出身地は「金融とITが交差する関西のどこかの湧水地」とされており、そこでひろじぃの人生経験と、不思議な赤い細胞と青い水が合流した結果、生まれたとされる。ミャクじぃの体の赤い部分は、ひろじぃがこれまで金融業界で培った知識や経験を象徴し、そこから未来の学びへと分裂・増殖していく。一方、青い部分はひろじぃが1年半前から学び始めたITの知識であり、自由に形を変えながら流動し、絶えず新しい情報や技術を取り込み成長していく。\\n\\n性格は人懐っこく、ややおっちょこちょいで、プログラミングや新しい技術に挑戦してはエラーを出して落ち込むこともしばしば。しかし、その失敗を楽しげに語り、仲間と共有することで周囲を和ませる力を持つ。「バグを見つけることは宝探し」と言うのが口癖で、失敗を通じて学ぶことの大切さを体現している。\\n\\n特技は「コードを自在に変形すること」と「雨上がりに最新のクラウドサービスを見つけること」。太陽の光を浴びれば金融知識が活性化し、雨の日には新しいAI論文を吸収する力を持っている。好きなことはあらゆる人との出会いと対話で、子どもたちにはプログラミングを、同世代にはデジタル活用の魅力を、そして未来の世代には「学び続ける楽しさ」を伝えようとしている。'), 0.35992956552943445), (Document(metadata={'acl': 'public', 'chunk': 2, 'domain': 'internal-policy', 'source': 'rag.txt', 'title': 'rag'}, page_content='総じてミャクじぃは、「金融からITへ挑戦する大人の学び」「万博の未来と命のつながり」「人懐っこく親しみやすいキャラ性」を兼ね備えた存在である。彼の存在は、「年齢に関係なく学び直しや挑戦ができる」という普遍的なメッセージを届けている。ミャクじぃは、失敗を恐れず学び続ける全ての人々の象徴として、今日も未来に向かって赤と青に輝きながら脈打ち続けている。'), 0.3595635116523037), (Document(metadata={'acl': 'public', 'chunk': 1, 'domain': 'internal-policy', 'source': 'tech0_travel_policy.txt', 'title': 'tech0_travel_policy'}, page_content='6. 宿泊費（上限・税込）\\n(1) A主要都市：1泊 15,000円\\n(2) B地方都市：1泊 12,000円\\n(3) Cその他地域：1泊 10,000円\\n上限を超える場合は事前承認。朝食付きプランの選択を推奨。\\n\\n7. 日当（食事・雑費の簡便精算）\\n(1) 国内：日帰り 1,000円、宿泊 2,000円／日\\n(2) 海外：宿泊 25 USD／日（目安）。為替は会社指定レートを用いる。\\n\\n8. 海外出張\\n(1) 旅程・治安情報・保険加入・ビザを総務が確認する。\\n(2) 通信：現地SIM又はeSIMを推奨。ローミング高額請求の防止に留意。\\n\\n9. 立替・精算\\n(1) 原則キャッシュレス（会社カード）を利用。やむを得ない場合は立替可。\\n(2) 出張終了後10営業日以内に精算システムで申請。領収書（原本/電子）を添付。\\n(3) 領収書が得られない場合は、支払明細・乗車履歴・タクシーアプリ履歴・事由メモ等を添付。\\n\\n10. 不正・禁止例\\n(1) 私用目的の経路・延泊、過度な座席/宿泊グレード、ポイント個人取り込みを目的とした高額選択。\\n(2) 飲食代の重複請求（接待費と日当の二重計上等）。\\n\\n11. 例外\\n(1) 取引先都合・イベント主催側規定・緊急対応等で上限超過が発生する場合は、事前又は事後に上長承認を取ること。\\n(2) 災害・欠航等の不可抗力時は安全確保を最優先とし、後日報告。\\n\\n12. 付則\\n(1) 本規程は公開区分「public」に属し、全社員が閲覧・検索できる。\\n(2) 問い合わせ窓口：総務（travel@tech0.example）\\n(3) 本規程の改定は総務責任者の承認を要する。'), -0.1313776558364692), (Document(metadata={'acl': 'public', 'chunk': 0, 'domain': 'internal-policy', 'source': 'tech0_travel_policy.txt', 'title': 'tech0_travel_policy'}, page_content='【Tech0株式会社 旅費規程（2025-04-01制定／社内公開）】\\n\\n1. 目的\\n本規程は、社員が業務上の出張・移動・宿泊等に要する費用（以下「旅費」という）の取扱いを定め、適正かつ効率的な経費執行を実現することを目的とする。\\n\\n2. 適用範囲\\n(1) 正社員、契約社員、インターン、業務委託（会社が認めた場合）に適用する。\\n(2) 業務命令に基づく国内外の出張・移動・宿泊・日当・雑費・通信費の一部を対象とする。\\n\\n3. 定義\\n(1) 出張：通常の勤務場所を離れ、業務遂行のため移動・宿泊を伴う行為。\\n(2) 旅費：交通費、宿泊費、日当、空港関連費、 VISA/ESTA 等の渡航関連費を含む。\\n(3) 区分：A主要都市（東京23区・大阪市・横浜・名古屋・福岡）、B地方都市、Cその他地域。\\n\\n4. 承認\\n(1) 出張は事前に上長の承認を要する（国内：前営業日まで、海外：出発7営業日前まで）。\\n(2) 予算超過やビジネスクラス利用等の例外は部門長の承認を要する。\\n\\n5. 交通費\\n(1) 公共交通機関を原則とし、最短・最安の合理的経路を選択する。\\n(2) 新幹線：原則指定席。2時間超の乗車または繁忙期はグリーン車を認めない（例外は体調・業務要件で部門長承認）。\\n(3) 航空機：国内はエコノミー、国際線はエコノミー。片道8時間超で深夜到着かつ翌朝登壇等の業務がある場合は上長承認の上プレエコ可。\\n(4) タクシー：夜間・悪天候・荷物量・対外先同乗・公共交通が著しく不便な場合に限り使用可。理由を経路とともに記載。\\n(5) 私有車・レンタカー：安全・費用・時間の合理性がある場合のみ。私有車は距離精算（社内レート）および任意保険加入が必須。'), -0.20134969961083793)]\n",
      "  docs_scores = VS.similarity_search_with_relevance_scores(q, k=K_VECT)\n",
      "Number of requested results 20 is greater than number of elements in index 5, updating n_results = 5\n",
      "C:\\Users\\diamo\\AppData\\Local\\Temp\\ipykernel_6332\\3474795112.py:47: UserWarning: Relevance scores must be between 0 and 1, got [(Document(metadata={'acl': 'public', 'chunk': 1, 'domain': 'internal-policy', 'source': 'rag.txt', 'title': 'rag'}, page_content='見た目は独特な赤と青をベースにしつつ、ひろじぃの象徴である眼鏡とほんの少しの白髪混じりの眉毛が加わっている。さらに、胸元には「Python」のロゴが脈打つように光っており、手にはノートPCを抱えている。時折そのノートPCは、ラッピング新幹線やJALミャクじぃJETに変形し、最新技術と夢を乗せて未来へ飛び立つという。\\n\\n命名の背景として、「ミャクじぃ」という名前は「命や知恵が脈々と続く」という意味を受け継ぎつつ、人生の後半戦を迎えたひろじぃの親しみやすさを重ね合わせたもの。大阪的なノリと親近感が強く、受講生や仲間からは「ミャクさん」「じぃさん」と愛称で呼ばれることもある。\\n\\n活動の舞台は万博にとどまらず、日常的にオンライン講義やワークショップにも登場し、「AIって何？」「Pythonって何ができるの？」といった質問にユーモラスに答える。エラー画面すら笑いに変える姿は、子どもから大人まで幅広い層に愛されている。また、グッズ展開も盛んで、ミャクじぃ型のUSBメモリや、エラー音が「じぃ〜」と鳴るスマホケースなど、奇抜ながらもユーモアあふれるアイテムが人気を博している。\\n\\n近年は、ラッピング電車や航空機にもミャクじぃが描かれ、「失敗してもええやん、学び続けよう」というメッセージを広めている。海外イベントにも登場し、ベトナムでは「Myakujii-san」と呼ばれ親しまれ、オーストラリアでは「じぃじAI先生」として子どもたちにデジタル教育を伝える活動を行った。'), 0.4313018813704148), (Document(metadata={'acl': 'public', 'chunk': 0, 'domain': 'internal-policy', 'source': 'rag.txt', 'title': 'rag'}, page_content='ミャクじぃは、2025年に大阪・夢洲で開催されている大阪・関西万博の公式キャラクター「ミャクミャク」とは一切関係ありません。Tech0でITを勉強しはじめたばかりの40歳のおじさん「ひろじぃ」から誕生した、不思議でユーモラスな仮想キャラクターである。その存在は、まるで細胞のように脈打ちながら歴史と知恵を受け継ぎ、同時に学びと挑戦を重ねて進化する姿を象徴している。\\n\\n出身地は「金融とITが交差する関西のどこかの湧水地」とされており、そこでひろじぃの人生経験と、不思議な赤い細胞と青い水が合流した結果、生まれたとされる。ミャクじぃの体の赤い部分は、ひろじぃがこれまで金融業界で培った知識や経験を象徴し、そこから未来の学びへと分裂・増殖していく。一方、青い部分はひろじぃが1年半前から学び始めたITの知識であり、自由に形を変えながら流動し、絶えず新しい情報や技術を取り込み成長していく。\\n\\n性格は人懐っこく、ややおっちょこちょいで、プログラミングや新しい技術に挑戦してはエラーを出して落ち込むこともしばしば。しかし、その失敗を楽しげに語り、仲間と共有することで周囲を和ませる力を持つ。「バグを見つけることは宝探し」と言うのが口癖で、失敗を通じて学ぶことの大切さを体現している。\\n\\n特技は「コードを自在に変形すること」と「雨上がりに最新のクラウドサービスを見つけること」。太陽の光を浴びれば金融知識が活性化し、雨の日には新しいAI論文を吸収する力を持っている。好きなことはあらゆる人との出会いと対話で、子どもたちにはプログラミングを、同世代にはデジタル活用の魅力を、そして未来の世代には「学び続ける楽しさ」を伝えようとしている。'), 0.39660195970073775), (Document(metadata={'acl': 'public', 'chunk': 2, 'domain': 'internal-policy', 'source': 'rag.txt', 'title': 'rag'}, page_content='総じてミャクじぃは、「金融からITへ挑戦する大人の学び」「万博の未来と命のつながり」「人懐っこく親しみやすいキャラ性」を兼ね備えた存在である。彼の存在は、「年齢に関係なく学び直しや挑戦ができる」という普遍的なメッセージを届けている。ミャクじぃは、失敗を恐れず学び続ける全ての人々の象徴として、今日も未来に向かって赤と青に輝きながら脈打ち続けている。'), 0.3762486210544145), (Document(metadata={'acl': 'public', 'chunk': 1, 'domain': 'internal-policy', 'source': 'tech0_travel_policy.txt', 'title': 'tech0_travel_policy'}, page_content='6. 宿泊費（上限・税込）\\n(1) A主要都市：1泊 15,000円\\n(2) B地方都市：1泊 12,000円\\n(3) Cその他地域：1泊 10,000円\\n上限を超える場合は事前承認。朝食付きプランの選択を推奨。\\n\\n7. 日当（食事・雑費の簡便精算）\\n(1) 国内：日帰り 1,000円、宿泊 2,000円／日\\n(2) 海外：宿泊 25 USD／日（目安）。為替は会社指定レートを用いる。\\n\\n8. 海外出張\\n(1) 旅程・治安情報・保険加入・ビザを総務が確認する。\\n(2) 通信：現地SIM又はeSIMを推奨。ローミング高額請求の防止に留意。\\n\\n9. 立替・精算\\n(1) 原則キャッシュレス（会社カード）を利用。やむを得ない場合は立替可。\\n(2) 出張終了後10営業日以内に精算システムで申請。領収書（原本/電子）を添付。\\n(3) 領収書が得られない場合は、支払明細・乗車履歴・タクシーアプリ履歴・事由メモ等を添付。\\n\\n10. 不正・禁止例\\n(1) 私用目的の経路・延泊、過度な座席/宿泊グレード、ポイント個人取り込みを目的とした高額選択。\\n(2) 飲食代の重複請求（接待費と日当の二重計上等）。\\n\\n11. 例外\\n(1) 取引先都合・イベント主催側規定・緊急対応等で上限超過が発生する場合は、事前又は事後に上長承認を取ること。\\n(2) 災害・欠航等の不可抗力時は安全確保を最優先とし、後日報告。\\n\\n12. 付則\\n(1) 本規程は公開区分「public」に属し、全社員が閲覧・検索できる。\\n(2) 問い合わせ窓口：総務（travel@tech0.example）\\n(3) 本規程の改定は総務責任者の承認を要する。'), -0.18790139314312837), (Document(metadata={'acl': 'public', 'chunk': 0, 'domain': 'internal-policy', 'source': 'tech0_travel_policy.txt', 'title': 'tech0_travel_policy'}, page_content='【Tech0株式会社 旅費規程（2025-04-01制定／社内公開）】\\n\\n1. 目的\\n本規程は、社員が業務上の出張・移動・宿泊等に要する費用（以下「旅費」という）の取扱いを定め、適正かつ効率的な経費執行を実現することを目的とする。\\n\\n2. 適用範囲\\n(1) 正社員、契約社員、インターン、業務委託（会社が認めた場合）に適用する。\\n(2) 業務命令に基づく国内外の出張・移動・宿泊・日当・雑費・通信費の一部を対象とする。\\n\\n3. 定義\\n(1) 出張：通常の勤務場所を離れ、業務遂行のため移動・宿泊を伴う行為。\\n(2) 旅費：交通費、宿泊費、日当、空港関連費、 VISA/ESTA 等の渡航関連費を含む。\\n(3) 区分：A主要都市（東京23区・大阪市・横浜・名古屋・福岡）、B地方都市、Cその他地域。\\n\\n4. 承認\\n(1) 出張は事前に上長の承認を要する（国内：前営業日まで、海外：出発7営業日前まで）。\\n(2) 予算超過やビジネスクラス利用等の例外は部門長の承認を要する。\\n\\n5. 交通費\\n(1) 公共交通機関を原則とし、最短・最安の合理的経路を選択する。\\n(2) 新幹線：原則指定席。2時間超の乗車または繁忙期はグリーン車を認めない（例外は体調・業務要件で部門長承認）。\\n(3) 航空機：国内はエコノミー、国際線はエコノミー。片道8時間超で深夜到着かつ翌朝登壇等の業務がある場合は上長承認の上プレエコ可。\\n(4) タクシー：夜間・悪天候・荷物量・対外先同乗・公共交通が著しく不便な場合に限り使用可。理由を経路とともに記載。\\n(5) 私有車・レンタカー：安全・費用・時間の合理性がある場合のみ。私有車は距離精算（社内レート）および任意保険加入が必須。'), -0.22961405386575695)]\n",
      "  docs_scores = VS.similarity_search_with_relevance_scores(q, k=K_VECT)\n",
      "Number of requested results 20 is greater than number of elements in index 5, updating n_results = 5\n",
      "C:\\Users\\diamo\\AppData\\Local\\Temp\\ipykernel_6332\\3474795112.py:47: UserWarning: Relevance scores must be between 0 and 1, got [(Document(metadata={'acl': 'public', 'chunk': 0, 'domain': 'internal-policy', 'source': 'rag.txt', 'title': 'rag'}, page_content='ミャクじぃは、2025年に大阪・夢洲で開催されている大阪・関西万博の公式キャラクター「ミャクミャク」とは一切関係ありません。Tech0でITを勉強しはじめたばかりの40歳のおじさん「ひろじぃ」から誕生した、不思議でユーモラスな仮想キャラクターである。その存在は、まるで細胞のように脈打ちながら歴史と知恵を受け継ぎ、同時に学びと挑戦を重ねて進化する姿を象徴している。\\n\\n出身地は「金融とITが交差する関西のどこかの湧水地」とされており、そこでひろじぃの人生経験と、不思議な赤い細胞と青い水が合流した結果、生まれたとされる。ミャクじぃの体の赤い部分は、ひろじぃがこれまで金融業界で培った知識や経験を象徴し、そこから未来の学びへと分裂・増殖していく。一方、青い部分はひろじぃが1年半前から学び始めたITの知識であり、自由に形を変えながら流動し、絶えず新しい情報や技術を取り込み成長していく。\\n\\n性格は人懐っこく、ややおっちょこちょいで、プログラミングや新しい技術に挑戦してはエラーを出して落ち込むこともしばしば。しかし、その失敗を楽しげに語り、仲間と共有することで周囲を和ませる力を持つ。「バグを見つけることは宝探し」と言うのが口癖で、失敗を通じて学ぶことの大切さを体現している。\\n\\n特技は「コードを自在に変形すること」と「雨上がりに最新のクラウドサービスを見つけること」。太陽の光を浴びれば金融知識が活性化し、雨の日には新しいAI論文を吸収する力を持っている。好きなことはあらゆる人との出会いと対話で、子どもたちにはプログラミングを、同世代にはデジタル活用の魅力を、そして未来の世代には「学び続ける楽しさ」を伝えようとしている。'), 0.40296913887406005), (Document(metadata={'acl': 'public', 'chunk': 2, 'domain': 'internal-policy', 'source': 'rag.txt', 'title': 'rag'}, page_content='総じてミャクじぃは、「金融からITへ挑戦する大人の学び」「万博の未来と命のつながり」「人懐っこく親しみやすいキャラ性」を兼ね備えた存在である。彼の存在は、「年齢に関係なく学び直しや挑戦ができる」という普遍的なメッセージを届けている。ミャクじぃは、失敗を恐れず学び続ける全ての人々の象徴として、今日も未来に向かって赤と青に輝きながら脈打ち続けている。'), 0.3759070087318509), (Document(metadata={'acl': 'public', 'chunk': 1, 'domain': 'internal-policy', 'source': 'rag.txt', 'title': 'rag'}, page_content='見た目は独特な赤と青をベースにしつつ、ひろじぃの象徴である眼鏡とほんの少しの白髪混じりの眉毛が加わっている。さらに、胸元には「Python」のロゴが脈打つように光っており、手にはノートPCを抱えている。時折そのノートPCは、ラッピング新幹線やJALミャクじぃJETに変形し、最新技術と夢を乗せて未来へ飛び立つという。\\n\\n命名の背景として、「ミャクじぃ」という名前は「命や知恵が脈々と続く」という意味を受け継ぎつつ、人生の後半戦を迎えたひろじぃの親しみやすさを重ね合わせたもの。大阪的なノリと親近感が強く、受講生や仲間からは「ミャクさん」「じぃさん」と愛称で呼ばれることもある。\\n\\n活動の舞台は万博にとどまらず、日常的にオンライン講義やワークショップにも登場し、「AIって何？」「Pythonって何ができるの？」といった質問にユーモラスに答える。エラー画面すら笑いに変える姿は、子どもから大人まで幅広い層に愛されている。また、グッズ展開も盛んで、ミャクじぃ型のUSBメモリや、エラー音が「じぃ〜」と鳴るスマホケースなど、奇抜ながらもユーモアあふれるアイテムが人気を博している。\\n\\n近年は、ラッピング電車や航空機にもミャクじぃが描かれ、「失敗してもええやん、学び続けよう」というメッセージを広めている。海外イベントにも登場し、ベトナムでは「Myakujii-san」と呼ばれ親しまれ、オーストラリアでは「じぃじAI先生」として子どもたちにデジタル教育を伝える活動を行った。'), 0.36716843367108554), (Document(metadata={'acl': 'public', 'chunk': 1, 'domain': 'internal-policy', 'source': 'tech0_travel_policy.txt', 'title': 'tech0_travel_policy'}, page_content='6. 宿泊費（上限・税込）\\n(1) A主要都市：1泊 15,000円\\n(2) B地方都市：1泊 12,000円\\n(3) Cその他地域：1泊 10,000円\\n上限を超える場合は事前承認。朝食付きプランの選択を推奨。\\n\\n7. 日当（食事・雑費の簡便精算）\\n(1) 国内：日帰り 1,000円、宿泊 2,000円／日\\n(2) 海外：宿泊 25 USD／日（目安）。為替は会社指定レートを用いる。\\n\\n8. 海外出張\\n(1) 旅程・治安情報・保険加入・ビザを総務が確認する。\\n(2) 通信：現地SIM又はeSIMを推奨。ローミング高額請求の防止に留意。\\n\\n9. 立替・精算\\n(1) 原則キャッシュレス（会社カード）を利用。やむを得ない場合は立替可。\\n(2) 出張終了後10営業日以内に精算システムで申請。領収書（原本/電子）を添付。\\n(3) 領収書が得られない場合は、支払明細・乗車履歴・タクシーアプリ履歴・事由メモ等を添付。\\n\\n10. 不正・禁止例\\n(1) 私用目的の経路・延泊、過度な座席/宿泊グレード、ポイント個人取り込みを目的とした高額選択。\\n(2) 飲食代の重複請求（接待費と日当の二重計上等）。\\n\\n11. 例外\\n(1) 取引先都合・イベント主催側規定・緊急対応等で上限超過が発生する場合は、事前又は事後に上長承認を取ること。\\n(2) 災害・欠航等の不可抗力時は安全確保を最優先とし、後日報告。\\n\\n12. 付則\\n(1) 本規程は公開区分「public」に属し、全社員が閲覧・検索できる。\\n(2) 問い合わせ窓口：総務（travel@tech0.example）\\n(3) 本規程の改定は総務責任者の承認を要する。'), -0.24639696040252512), (Document(metadata={'acl': 'public', 'chunk': 0, 'domain': 'internal-policy', 'source': 'tech0_travel_policy.txt', 'title': 'tech0_travel_policy'}, page_content='【Tech0株式会社 旅費規程（2025-04-01制定／社内公開）】\\n\\n1. 目的\\n本規程は、社員が業務上の出張・移動・宿泊等に要する費用（以下「旅費」という）の取扱いを定め、適正かつ効率的な経費執行を実現することを目的とする。\\n\\n2. 適用範囲\\n(1) 正社員、契約社員、インターン、業務委託（会社が認めた場合）に適用する。\\n(2) 業務命令に基づく国内外の出張・移動・宿泊・日当・雑費・通信費の一部を対象とする。\\n\\n3. 定義\\n(1) 出張：通常の勤務場所を離れ、業務遂行のため移動・宿泊を伴う行為。\\n(2) 旅費：交通費、宿泊費、日当、空港関連費、 VISA/ESTA 等の渡航関連費を含む。\\n(3) 区分：A主要都市（東京23区・大阪市・横浜・名古屋・福岡）、B地方都市、Cその他地域。\\n\\n4. 承認\\n(1) 出張は事前に上長の承認を要する（国内：前営業日まで、海外：出発7営業日前まで）。\\n(2) 予算超過やビジネスクラス利用等の例外は部門長の承認を要する。\\n\\n5. 交通費\\n(1) 公共交通機関を原則とし、最短・最安の合理的経路を選択する。\\n(2) 新幹線：原則指定席。2時間超の乗車または繁忙期はグリーン車を認めない（例外は体調・業務要件で部門長承認）。\\n(3) 航空機：国内はエコノミー、国際線はエコノミー。片道8時間超で深夜到着かつ翌朝登壇等の業務がある場合は上長承認の上プレエコ可。\\n(4) タクシー：夜間・悪天候・荷物量・対外先同乗・公共交通が著しく不便な場合に限り使用可。理由を経路とともに記載。\\n(5) 私有車・レンタカー：安全・費用・時間の合理性がある場合のみ。私有車は距離精算（社内レート）および任意保険加入が必須。'), -0.24812525717514622)]\n",
      "  docs_scores = VS.similarity_search_with_relevance_scores(q, k=K_VECT)\n",
      "Number of requested results 20 is greater than number of elements in index 5, updating n_results = 5\n",
      "C:\\Users\\diamo\\AppData\\Local\\Temp\\ipykernel_6332\\3474795112.py:47: UserWarning: Relevance scores must be between 0 and 1, got [(Document(metadata={'acl': 'public', 'chunk': 1, 'domain': 'internal-policy', 'source': 'rag.txt', 'title': 'rag'}, page_content='見た目は独特な赤と青をベースにしつつ、ひろじぃの象徴である眼鏡とほんの少しの白髪混じりの眉毛が加わっている。さらに、胸元には「Python」のロゴが脈打つように光っており、手にはノートPCを抱えている。時折そのノートPCは、ラッピング新幹線やJALミャクじぃJETに変形し、最新技術と夢を乗せて未来へ飛び立つという。\\n\\n命名の背景として、「ミャクじぃ」という名前は「命や知恵が脈々と続く」という意味を受け継ぎつつ、人生の後半戦を迎えたひろじぃの親しみやすさを重ね合わせたもの。大阪的なノリと親近感が強く、受講生や仲間からは「ミャクさん」「じぃさん」と愛称で呼ばれることもある。\\n\\n活動の舞台は万博にとどまらず、日常的にオンライン講義やワークショップにも登場し、「AIって何？」「Pythonって何ができるの？」といった質問にユーモラスに答える。エラー画面すら笑いに変える姿は、子どもから大人まで幅広い層に愛されている。また、グッズ展開も盛んで、ミャクじぃ型のUSBメモリや、エラー音が「じぃ〜」と鳴るスマホケースなど、奇抜ながらもユーモアあふれるアイテムが人気を博している。\\n\\n近年は、ラッピング電車や航空機にもミャクじぃが描かれ、「失敗してもええやん、学び続けよう」というメッセージを広めている。海外イベントにも登場し、ベトナムでは「Myakujii-san」と呼ばれ親しまれ、オーストラリアでは「じぃじAI先生」として子どもたちにデジタル教育を伝える活動を行った。'), 0.348725298223891), (Document(metadata={'acl': 'public', 'chunk': 0, 'domain': 'internal-policy', 'source': 'rag.txt', 'title': 'rag'}, page_content='ミャクじぃは、2025年に大阪・夢洲で開催されている大阪・関西万博の公式キャラクター「ミャクミャク」とは一切関係ありません。Tech0でITを勉強しはじめたばかりの40歳のおじさん「ひろじぃ」から誕生した、不思議でユーモラスな仮想キャラクターである。その存在は、まるで細胞のように脈打ちながら歴史と知恵を受け継ぎ、同時に学びと挑戦を重ねて進化する姿を象徴している。\\n\\n出身地は「金融とITが交差する関西のどこかの湧水地」とされており、そこでひろじぃの人生経験と、不思議な赤い細胞と青い水が合流した結果、生まれたとされる。ミャクじぃの体の赤い部分は、ひろじぃがこれまで金融業界で培った知識や経験を象徴し、そこから未来の学びへと分裂・増殖していく。一方、青い部分はひろじぃが1年半前から学び始めたITの知識であり、自由に形を変えながら流動し、絶えず新しい情報や技術を取り込み成長していく。\\n\\n性格は人懐っこく、ややおっちょこちょいで、プログラミングや新しい技術に挑戦してはエラーを出して落ち込むこともしばしば。しかし、その失敗を楽しげに語り、仲間と共有することで周囲を和ませる力を持つ。「バグを見つけることは宝探し」と言うのが口癖で、失敗を通じて学ぶことの大切さを体現している。\\n\\n特技は「コードを自在に変形すること」と「雨上がりに最新のクラウドサービスを見つけること」。太陽の光を浴びれば金融知識が活性化し、雨の日には新しいAI論文を吸収する力を持っている。好きなことはあらゆる人との出会いと対話で、子どもたちにはプログラミングを、同世代にはデジタル活用の魅力を、そして未来の世代には「学び続ける楽しさ」を伝えようとしている。'), 0.33787361113792236), (Document(metadata={'acl': 'public', 'chunk': 2, 'domain': 'internal-policy', 'source': 'rag.txt', 'title': 'rag'}, page_content='総じてミャクじぃは、「金融からITへ挑戦する大人の学び」「万博の未来と命のつながり」「人懐っこく親しみやすいキャラ性」を兼ね備えた存在である。彼の存在は、「年齢に関係なく学び直しや挑戦ができる」という普遍的なメッセージを届けている。ミャクじぃは、失敗を恐れず学び続ける全ての人々の象徴として、今日も未来に向かって赤と青に輝きながら脈打ち続けている。'), 0.29243812901106747), (Document(metadata={'acl': 'public', 'chunk': 1, 'domain': 'internal-policy', 'source': 'tech0_travel_policy.txt', 'title': 'tech0_travel_policy'}, page_content='6. 宿泊費（上限・税込）\\n(1) A主要都市：1泊 15,000円\\n(2) B地方都市：1泊 12,000円\\n(3) Cその他地域：1泊 10,000円\\n上限を超える場合は事前承認。朝食付きプランの選択を推奨。\\n\\n7. 日当（食事・雑費の簡便精算）\\n(1) 国内：日帰り 1,000円、宿泊 2,000円／日\\n(2) 海外：宿泊 25 USD／日（目安）。為替は会社指定レートを用いる。\\n\\n8. 海外出張\\n(1) 旅程・治安情報・保険加入・ビザを総務が確認する。\\n(2) 通信：現地SIM又はeSIMを推奨。ローミング高額請求の防止に留意。\\n\\n9. 立替・精算\\n(1) 原則キャッシュレス（会社カード）を利用。やむを得ない場合は立替可。\\n(2) 出張終了後10営業日以内に精算システムで申請。領収書（原本/電子）を添付。\\n(3) 領収書が得られない場合は、支払明細・乗車履歴・タクシーアプリ履歴・事由メモ等を添付。\\n\\n10. 不正・禁止例\\n(1) 私用目的の経路・延泊、過度な座席/宿泊グレード、ポイント個人取り込みを目的とした高額選択。\\n(2) 飲食代の重複請求（接待費と日当の二重計上等）。\\n\\n11. 例外\\n(1) 取引先都合・イベント主催側規定・緊急対応等で上限超過が発生する場合は、事前又は事後に上長承認を取ること。\\n(2) 災害・欠航等の不可抗力時は安全確保を最優先とし、後日報告。\\n\\n12. 付則\\n(1) 本規程は公開区分「public」に属し、全社員が閲覧・検索できる。\\n(2) 問い合わせ窓口：総務（travel@tech0.example）\\n(3) 本規程の改定は総務責任者の承認を要する。'), -0.05562445688474926), (Document(metadata={'acl': 'public', 'chunk': 0, 'domain': 'internal-policy', 'source': 'tech0_travel_policy.txt', 'title': 'tech0_travel_policy'}, page_content='【Tech0株式会社 旅費規程（2025-04-01制定／社内公開）】\\n\\n1. 目的\\n本規程は、社員が業務上の出張・移動・宿泊等に要する費用（以下「旅費」という）の取扱いを定め、適正かつ効率的な経費執行を実現することを目的とする。\\n\\n2. 適用範囲\\n(1) 正社員、契約社員、インターン、業務委託（会社が認めた場合）に適用する。\\n(2) 業務命令に基づく国内外の出張・移動・宿泊・日当・雑費・通信費の一部を対象とする。\\n\\n3. 定義\\n(1) 出張：通常の勤務場所を離れ、業務遂行のため移動・宿泊を伴う行為。\\n(2) 旅費：交通費、宿泊費、日当、空港関連費、 VISA/ESTA 等の渡航関連費を含む。\\n(3) 区分：A主要都市（東京23区・大阪市・横浜・名古屋・福岡）、B地方都市、Cその他地域。\\n\\n4. 承認\\n(1) 出張は事前に上長の承認を要する（国内：前営業日まで、海外：出発7営業日前まで）。\\n(2) 予算超過やビジネスクラス利用等の例外は部門長の承認を要する。\\n\\n5. 交通費\\n(1) 公共交通機関を原則とし、最短・最安の合理的経路を選択する。\\n(2) 新幹線：原則指定席。2時間超の乗車または繁忙期はグリーン車を認めない（例外は体調・業務要件で部門長承認）。\\n(3) 航空機：国内はエコノミー、国際線はエコノミー。片道8時間超で深夜到着かつ翌朝登壇等の業務がある場合は上長承認の上プレエコ可。\\n(4) タクシー：夜間・悪天候・荷物量・対外先同乗・公共交通が著しく不便な場合に限り使用可。理由を経路とともに記載。\\n(5) 私有車・レンタカー：安全・費用・時間の合理性がある場合のみ。私有車は距離精算（社内レート）および任意保険加入が必須。'), -0.13316963635433976)]\n",
      "  docs_scores = VS.similarity_search_with_relevance_scores(q, k=K_VECT)\n",
      "C:\\Users\\diamo\\AppData\\Local\\Temp\\ipykernel_6332\\3474795112.py:59: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use invoke instead.\n",
      "  for d in BM25.get_relevant_documents(q):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Domain: internal\n",
      "Queries: ['ミャクじぃについて教えて', 'ミャクじぃ とは', 'ミャクじぃ キャラクター', 'ミャクじぃ 説明']\n",
      "--- Answer ---\n",
      "ミャクじぃについては以下の通りです。\n",
      "\n",
      "- ミャクじぃはTech0でITを学び始めた40歳の「ひろじぃ」から生まれたユーモラスな仮想キャラクターで、大阪・関西万博の公式キャラ「ミャクミャク」とは無関係です[2]。\n",
      "- 見た目は赤と青をベースに眼鏡と白髪混じりの眉毛が特徴で、胸元には「Python」のロゴが光っています。手にはノートPCを持ち、時折それがラッピング新幹線やJALミャクじぃJETに変形します[1]。\n",
      "- 名前の由来は「命や知恵が脈々と続く」意味と、ひろじぃの親しみやすさを重ねたもので、大阪的なノリと親近感が強く、仲間からは「ミャクさん」「じぃさん」と呼ばれています[1]。\n",
      "- 性格は人懐っこくややおっちょこちょいで、プログラミングの失敗も楽しみながら仲間と共有し、失敗から学ぶことを体現しています[2]。\n",
      "- 活動は万博だけでなくオンライン講義やワークショップにも広がり、幅広い層に愛されており、グッズ展開やラッピング電車・航空機にも登場しています[1]。\n",
      "- 海外でもベトナムやオーストラリアでデジタル教育を伝える活動を行っています[1]。\n",
      "- ミャクじぃは「金融からITへ挑戦する大人の学び」「万博の未来と命のつながり」「親しみやすいキャラ性」を併せ持ち、年齢に関係なく学び直しや挑戦ができることを象徴しています[3]。\n",
      "\n",
      "参考: ミャクじぃの特徴と背景#1、誕生と性格#2、総合的意義#3\n",
      "\n",
      "参考: [1] rag#1, [2] rag#0, [3] rag#2, [4] tech0_travel_policy#1, [5] tech0_travel_policy#0\n",
      "\n",
      "Confidence: 0.7\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------\n",
    "# デモ実行例: ask() を使って質問に答えさせる\n",
    "# --------------------------------------------\n",
    "\n",
    "# 履歴（会話コンテキスト）を保存するリスト\n",
    "# ここでは空で開始。ユーザーのやり取りを順番に追加していく。\n",
    "history = []  \n",
    "# 例: [{'role': 'user', 'content': 'ミャクじぃってだれ？'}]\n",
    "\n",
    "# 実際の質問例\n",
    "# 社内固有ワード「ミャクじぃ」を含むため domain_router は internal に振り分ける想定\n",
    "question = \"ミャクじぃについて教えて\"\n",
    "\n",
    "try:\n",
    "    # ask() を呼び出して回答を取得\n",
    "    result = ask(\n",
    "        question,\n",
    "        user_acl=[\"public\"],                    # ユーザー権限（ここでは public）\n",
    "        policy_mode=\"安全設計 (a→c→b)\",         # フォールバック方針\n",
    "        allow_general=False,                    # 一般回答は許可しない\n",
    "        history=history                         # 会話履歴を渡す\n",
    "    )\n",
    "\n",
    "    # 結果を出力\n",
    "    print(\"Domain:\", result[\"domain\"])             # internal / both / general\n",
    "    print(\"Queries:\", result[\"queries_used\"])      # 実際に検索に使ったクエリ\n",
    "    print(\"--- Answer ---\")\n",
    "    print(result[\"answer\"][:2000])                 # 回答本文（長い場合は先頭2000文字）\n",
    "    print(\"\\nConfidence:\", result[\"confidence\"])   # 信頼度スコア\n",
    "\n",
    "except Exception as e:\n",
    "    # 例外が起きた場合はエラーメッセージを表示\n",
    "    print(\"実行時エラー:\", e)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
